import pandas as pd
import json
import time
from sklearn.preprocessing import MinMaxScaler
import ssl
import certifi
from google import genai
import streamlit as st
from io import BytesIO
from pathlib import Path
import requests
import os
import concurrent.futures
from langchain.agents import Tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import openpyxl
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
import base64
from datetime import datetime

API_KEYS = [
    "AIzaSyD09_gws5tBYZmD0YHF1etSZ7K-7wePIh0",
    "AIzaSyBJ2N1RHTTTQMXUod7jPymZwbgnPsdgLsY",
    "AIzaSyBwvI4kSZWOnWG3Km6kpUbqD87wIUVcoHs",
    "AIzaSyDKvI5lwfrihbcXXaXxaQWhGULE77afyrg",
    "AIzaSyCxpTPYFq91HfeUVqe8JD3RjiU4nV63WH8",
    "AIzaSyCWZVz-ciOp91vKr2u7J87IktK2skygOro",
    "AIzaSyB11u1-TTuvIRNhSAp44PgWWpoK9kq1mAo",
    "AIzaSyBxusefsMEbKv6HAoYxECpOIqbKO-pCs2g",
    "AIzaSyDIAYd4QdTBQO4MVOnAvoA5tNEozVYdflE",
    "AIzaSyBw6zUcIsp5t4QZxI_BRiPphYJzf7mq8p4",
    "AIzaSyC3EpZaqKLQwxCGUxKLzuwzvtKT2EjYTEA",
    "AIzaSyAkXdS9nAA35pdOX4kZQaFOgOznjU9MlDs",
    "AIzaSyBZqnpTMHL8Zap2CIrqifqXVA5YB30Apuw",
    "AIzaSyBqTtltNANsAhbodnxfFJOFq8vaGszJPqQ",
    "AIzaSyCC2RTsg8ArBgXj8t82-w-agFE82s0CUHw",
    "AIzaSyDvtLtNuVVlgNBvzwPRl42RyWZJqRsCI4Q",
    "AIzaSyATYlQN6L7SJz7mY7wScnyB8G_DqRsJQT4",
    "AIzaSyBW8Q1amjzs0_XLHaKaecyZuQJe0U5qhZU",
    "AIzaSyA7YtWUSsljlQuWOuy3fSBajot2rI5D3e8",
    "AIzaSyAsFagF5Z-A_o2pvUiAwpzqXpDpRNjhwfM",
    "AIzaSyDG8LTKH4NGqQcaGAz76z4hKAQ95jVjz4c",
    "AIzaSyDwB9W3SJjG5qkTd58L8ToX0xmi57Kh8d4",
    "AIzaSyBNAb6TSR4mhq82WtW2wHSCOUDK73IDbfs",
    "AIzaSyB51i5YnENFBE8aYncinPtwLk1dThl2CuA"
]

def load_font(font_path):
    """Load font file and convert to base64"""
    if os.path.exists(font_path):
        with open(font_path, "rb") as f:
            font_data = f.read()
        return base64.b64encode(font_data).decode()
    return None

# Load Nazanin fonts from your repository
font_regular = load_font("0 Nazanin.TTF")
font_bold = load_font("0 Nazanin Bold.TTF")

if font_regular and font_bold:
    font_css = f"""
    <style>
      @font-face {{
        font-family: 'Nazanin';
        src: url(data:font/truetype;charset=utf-8;base64,{font_regular}) format('truetype');
        font-weight: normal;
        font-style: normal;
      }}

      @font-face {{
        font-family: 'Nazanin';
        src: url(data:font/truetype;charset=utf-8;base64,{font_bold}) format('truetype');
        font-weight: bold;
        font-style: normal;
      }}

      html, body, [class^="st-"], [class*=" st-"], .block-container {{
        font-family: 'Nazanin', Tahoma, sans-serif !important;
        direction: rtl !important;
        text-align: right !important;
      }}
      
      /* Target all Streamlit elements */
      .stButton > button {{
        font-family: 'Nazanin', Tahoma, sans-serif !important;
      }}
      
      .stSelectbox label, .stMultiSelect label, .stTextInput label {{
        font-family: 'Nazanin', Tahoma, sans-serif !important;
      }}
      
      div[data-testid="stDataFrame"] * {{
        font-family: 'Nazanin', Tahoma, sans-serif !important;
      }}
    </style>
    """
    st.markdown(font_css, unsafe_allow_html=True)
else:
    st.warning("ÙÙˆÙ†Øª Nazanin ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² ÙÙˆÙ†Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")


def style_excel(path): 
    wb = openpyxl.load_workbook(path) 
    ws = wb.active 

    header_fill = PatternFill(start_color="B7DEE8", end_color="B7DEE8", fill_type="solid")
    row_fill_odd = PatternFill(start_color="FFFFFF", end_color="FFFFFF", fill_type="solid")
    row_fill_even = PatternFill(start_color="EAF3FA", end_color="EAF3FA", fill_type="solid")

    header_font = Font(bold=True, name='B Homa', size=14)
    row_font = Font(name='B Homa', size=12)
    center_align = Alignment(horizontal="center", vertical="center", wrap_text=True)

    border = Border(
        left=Side(border_style="thin", color="CCCCCC"),
        right=Side(border_style="thin", color="CCCCCC"),
        top=Side(border_style="thin", color="CCCCCC"),
        bottom=Side(border_style="thin", color="CCCCCC"),
    )

    for cell in ws[1]:
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = center_align
        cell.border = border

    for idx, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column), start=2):
        fill = row_fill_even if idx % 2 == 0 else row_fill_odd
        for cell in row:
            cell.fill = fill
            cell.font = row_font
            cell.alignment = center_align
            cell.border = border

    for col in ws.columns:
        if col[0].value == "ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ":
            for cell in col:
                cell.alignment = Alignment(wrap_text=True, vertical="top", horizontal="center")

    for col in ws.columns: 
        max_length = 0 
        column = col[0].column_letter 
        for cell in col: 
            try: 
                if cell.value:
                    max_length = max(max_length, len(str(cell.value))) 
            except: 
                pass 
        adjusted_width = min(max_length + 3, 50) 
        ws.column_dimensions[column].width = adjusted_width 

    ws.freeze_panes = ws["A2"] 

    wb.save(path)


class RotatingGeminiLLM:
    def __init__(self, api_keys, model="gemini-2.5-flash"):
        self.api_keys = api_keys
        self.model = model
        self.idx = 0

    def invoke(self, messages):
        num_keys = len(self.api_keys)
        start_idx = self.idx
        for i in range(num_keys):
            api_key = self.api_keys[self.idx]
            llm = ChatGoogleGenerativeAI(model=self.model, google_api_key=api_key)
            try:
                result = llm.invoke(messages)
                return result
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¨Ø§ API {api_key[:10]}...: {str(e)}")
                self.idx = (self.idx + 1) % num_keys
                if self.idx == start_idx:
                    raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")
        raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")

rotating_llm = RotatingGeminiLLM(API_KEYS)

def safe_generate_content(*, model, contents, config):
    for api_key in API_KEYS:
        try:
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model=model,
                contents=contents,
                config=config
            )
            return response
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¨Ø§ API {api_key[:10]}...: {str(e)}")
            continue
    raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key="AIzaSyC8tN4kY2QU5ACRacPazzRQeJPtAC08Vm8")

RESULT_FILE_PATH = Path("resume_results.xlsx")
if RESULT_FILE_PATH.exists():
    RESULT_FILE_PATH.unlink()

os.environ['SSL_CERT_FILE'] = certifi.where()

proxy_url = "http://172.16.217.234:33525"
os.environ['HTTP_PROXY'] = proxy_url
os.environ['HTTPS_PROXY'] = proxy_url

test_url = "https://generativelanguage.googleapis.com/v1beta/models"
try:
    response = requests.get(test_url, proxies={"http": proxy_url, "https": proxy_url}, timeout=5)
    if response.status_code == 200:
        print("âœ… Ø§ØªØµØ§Ù„ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª.")
    else:
        print(f"âš ï¸ Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {response.status_code}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ù¾Ø±Ø§Ú©Ø³ÛŒ: {e}")

pd.set_option('display.max_rows', None)
OUTPUT_ALL_PATH = Path("recruitment_score.xlsx")
BATCH_SIZE = 10
RESULT_FILE_PATH = Path("resume_results.xlsx")

if 'live_results' not in st.session_state:
    st.session_state['live_results'] = []

JOB_PROFILES = [
    {
        "id": "job_rnd_01",
        "title": "ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ø­ØµØ§ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø°ÛŒÙ†ÙØ¹Ø§Ù† Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø²ÛŒØ±Ø³Ø§Ø®Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø¬ÛŒÙ…ØŒ Ù„Ø§Ú¯ Ùˆ Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø±",
            "ØªÙˆØ³Ø¹Ù‡ Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø´Ø§Ù…Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒØŒ Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø± Ùˆ Ù¾Ø±ØªØ§Ù„",
            "Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø²ÛŒØ±Ø³Ø§Ø®Øª Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§",
            "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø´Øª Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ùˆ Ù¾Ø§Ø³Ø® Ø¨Ù‡ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ø´ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§"
        ],
        "competencies_technical": [
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ùˆ Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"},
            {"name": "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±"},
            {"name": "Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø¨Ú©â€ŒØ§Ù†Ø¯ ÛŒØ§ ÙØ±Ø§Ù†Øª (Ù…Ø«Ù„ Python ÛŒØ§ JavaScript)"},
            {"name": "Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"}
        ],
        "majors": ["Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ ÙÙ†ÛŒ Ùˆ Ù…Ù‡Ù†Ø¯Ø³ÛŒ"]
    },
    {
        "id": "job_spatial_01",
        "title": "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ú©Ø§Ù†ÛŒ",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ù…Ú©Ø§Ù†ÛŒ",
            "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ GIS Ùˆ RS",
            "ÙØ±Ø§ÛŒÙ†Ø¯ ETL Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒ",
            "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± GIS/RS",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ Ùˆ Ù…Ø§Ù…ÙˆØ±ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒ"
        ],
        "competencies_technical": [
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ø³Ù†Ø¬Ø´ Ø§Ø² Ø¯ÙˆØ±"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ RS Ù…Ø§Ù†Ù†Ø¯ ENVIØŒ ERDASØŒ SNAP"},
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ / Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±"},
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Python / MATLAB"},
            {"name": "Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ GIS Ù…Ø§Ù†Ù†Ø¯ ArcGIS/QGIS"}
        ],
        "majors": ["Ù†Ù‚Ø´Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¨Ø±Ù‚"]
    },
    {
        "id": "job_ai_01",
        "title": "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ø¨Ø§ ØªØ§Ú©ÛŒØ¯ Ø¨Ø± AI",
            "Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†",
            "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ MLOps",
            "ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´Ø§Øª ØªØ­Ù„ÛŒÙ„ÛŒ",
            "Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ø´ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ AI"
        ],
        "competencies_technical": [
            {"name": "Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¢Ù…Ø§Ø±ÛŒ / ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†"},
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Python / R / GAMS"},
            {"name": "Ú©Ø§Ø± Ø¨Ø§ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"}
        ],
        "majors": ["Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ø±ÛŒØ§Ø¶ÛŒ", "Ø¢Ù…Ø§Ø±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø§Ù‚ØªØµØ§Ø¯", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù…Ø§Ù„ÛŒ", "Ø¨Ø±Ù‚"]
    },
    {
        "id": "job_research_01",
        "title": "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø±Ø§Ú©Ø² Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ",
        "tasks": [
            "Ø§Ø­ØµØ§ Ù…Ø³Ø§Ø¦Ù„ ÙÙ†Ø§ÙˆØ±Ø§Ù†Ù‡ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ±",
            "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø³Ø§Ù…Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ Ù†Ø¸Ø§Ù… Ù…Ø³Ø§Ø¦Ù„",
            "Ù…Ø·Ø§Ù„Ø¹Ø§Øª ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§Ù‡Ø¨Ø±Ø¯ÛŒ AI",
            "Ø±ØµØ¯ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ¸Ù‡ÙˆØ±"
        ],
        "competencies_technical": [
            {"name": "Microsoft Office"},
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù… Ø¯Ø§Ø¯Ù‡ Ùˆ IT"},
            {"name": "Ø§ØµÙˆÙ„ ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡"}
        ],
        "majors": ["Ù…Ø¯ÛŒØ±ÛŒØª", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÛŒ", "Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"]
    },
    {
        "id": "job_analysis_01",
        "title": "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ùˆ Ù‡ÙˆØ´ ØªØ¬Ø§Ø±ÛŒ",
        "tasks": [
            "Ú¯Ø±ÙˆÙ‡ Ø¨Ù†Ø¯ÛŒ Ùˆ Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª",
            "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø±",
            "ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ ETL",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§Ù‡Ø¨Ø±Ø¯ÛŒ ",
            "Ù†Ø§Ù…Ù‡ Ù†Ú¯Ø§Ø±ÛŒ Ùˆ Ù…Ú©Ø§ØªØ¨Ø§Øª Ø§Ø¯Ø§Ø±ÛŒ",
            "Ø¨ØµØ±ÛŒ Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§"
        ],
        "competencies_technical": [
            {"name": "Microsoft Office"},
            {"name": "Ø´Ù†Ø§Ø®Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø±"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ù…Ø§Ù†Ù†Ø¯ powerBI"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù…Ø§Ù†Ù†Ø¯ KNIME"},
            {"name": "Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ Ø²Ø§Ù† Ù‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†ÙˆÛŒØ³ÛŒ Ù…Ø§Ù†Ù†Ø¯ python , R"}
        ],
        "majors": ["Ù…Ø¯ÛŒØ±ÛŒØª", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÛŒ", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"]
    }
]

universities_info = [
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù† (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø´Ø±ÛŒÙ (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ± (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª Ø§ÛŒØ±Ø§Ù† (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø¬Ù‡ Ù†ØµÛŒØ± (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ÙØ±Ø¯ÙˆØ³ÛŒ Ù…Ø´Ù‡Ø¯ (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªØ¨Ø±ÛŒØ² (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø§ØµÙÙ‡Ø§Ù† (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§ØµÙÙ‡Ø§Ù† (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¢Ø²Ø§Ø¯ Ø§Ø³Ù„Ø§Ù…ÛŒ (Ø¢Ø²Ø§Ø¯)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ù¾ÛŒØ§Ù… Ù†ÙˆØ± (Ù¾ÛŒØ§Ù… Ù†ÙˆØ±)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ (ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ (Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ)"
]

AGENT_WEIGHTS = {
    "SkillAgent": 0.40,
    "ExperienceAgent": 0.30,
    "EducationAgent": 0.20,
    "VolunteeringAgent": 0.05,
    "SoftSkillsAgent": 0.05
}

def score_text_section(text): 
    if not text or str(text).strip() == "": 
        return 30

    prompt = f"""  
    Please rate the quality of the following resume section on a scale of 0 to 100.  
    Consider clarity, relevance, and value in a resume.  
    Return only a number between 0.0 and 1.0.  

    Text: 
    \"\"\" 
    {text} 
    \"\"\" 
    """ 

    try: 
        response = llm.invoke([HumanMessage(content=prompt)]) 
        score = float(response.content.strip()) 
        return round(max(0.0, min(1.0, score)) * 100, 2)
    except: 
        return 30

def process_batch(batch_df, prompt_text):
    payload = {
        "employer requirements": prompt_text,
        "applicant information": [
            {"resume": " ".join([str(row[col]) for col in batch_df.columns]), "id": str(idx)}
            for idx, row in batch_df.iterrows()
        ]
    }
    try:
        response = safe_generate_content(
            model='gemini-2.5-flash',
            contents=json.dumps(payload, ensure_ascii=False),
            config={
                'response_mime_type': 'application/json',
                'system_instruction': """
Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:
- ØªØ·Ø§Ø¨Ù‚ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ
- ØªØ·Ø§Ø¨Ù‚ Ø³ÙˆØ§Ø¨Ù‚ Ø´ØºÙ„ÛŒ
- Ù…Ù‚Ø·Ø¹ Ùˆ Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ Ù…Ø±ØªØ¨Ø·
- Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¯ÙˆÙ„ØªÛŒ Ùˆ Ù…Ø¹ØªØ¨Ø±
- Ø³Ù† Ù…Ù†Ø§Ø³Ø¨ (Û²Û² ØªØ§ Û³Ûµ)
- Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ (Û²Û° ØªØ§ Û´Ûµ Ù…ÛŒÙ„ÛŒÙˆÙ†)
Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† Û± ØªØ§ Û±Û° Ø¨Ø¯Ù‡ÛŒØ¯. Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯: 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª'.
""",
                'response_schema': {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "score": {"type": "number", "nullable": False},
                            "check_id": {"type": "string", "nullable": False},
                            "why": {"type": "string", "nullable": False}
                        }
                    }
                },
                'temperature': 0
            }
        )
        result = json.loads(response.candidates[0].content.parts[0].text)
        return pd.DataFrame(result)
    except Exception:
        return pd.DataFrame([{
            "score": 1.0,
            "check_id": str(idx),
            "why": "Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª"
        } for idx, row in batch_df.iterrows()])

def to_excel(df, path):
    df.to_excel(path, index=False)

def match_resume_to_job_parallel(resume_text, job_profiles, threshold=7):
    best_match = None
    best_score = -1
    best_reason = ""
    log_messages = []

    def evaluate_job_with_key(api_key, job):
        prompt = f"""Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ±:
Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ:
Ø¹Ù†ÙˆØ§Ù†: {job['title']}
Ø´Ø±Ø­ ÙˆØ¸Ø§ÛŒÙ: {'Ø› '.join(job['tasks'])}
Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ: {'Ø› '.join([c['name'] for c in job.get('competencies_technical', [])])}
Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {'Ø› '.join(job.get('majors', []))}

Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ø§ÛŒÙ† Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ ØªØ·Ø§Ø¨Ù‚ Ø¯Ø§Ø±Ø¯ØŸ Ù„Ø·ÙØ§Ù‹:
- ÛŒÚ© Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† Û° ØªØ§ 100 Ø¨Ø¯Ù‡
- Ø¯Ø± ØµÙˆØ±Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù†ØŒ Ø¯Ù„ÛŒÙ„ Ø±Ø§ Ø´Ø±Ø­ Ø¨Ø¯Ù‡
- Ø¯Ø± ØµÙˆØ±Øª Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù†ØŒ Ø¨Ù†ÙˆÛŒØ³ Ú†Ø±Ø§ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª

Ù„Ø·ÙØ§Ù‹ Ù‡Ù…ÛŒØ´Ù‡ Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ø²ÛŒØ± Ùˆ Ø¨Ø§ Ù‡Ø±Ø¯Ùˆ Ø¨Ø®Ø´ Ø¨Ø¯Ù‡:
Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯ Ø§Ø² 0 ØªØ§ 100]
Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ ÙˆØ§Ø¶Ø­ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø´Ø§Ù…Ù„ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ ÛŒØ§ Ø¹Ø¯Ù… Ø§Ù†ØªØ®Ø§Ø¨]

"""
        try:
            response = safe_generate_content_for_key(
                api_key=api_key,
                model="gemini-2.5-flash",
                contents=prompt,
                config={"temperature": 0}
            )
            if isinstance(response, dict) and "error" in response:
                return None

            text = response.candidates[0].content.parts[0].text.strip()
            lines = [line.strip() for line in text.splitlines() if line.strip() != ""]

            score = -1
            reason = "ØªÙˆØ¶ÛŒØ­ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"

            for line in lines:
                if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
                    try:
                        score = int("".join(filter(str.isdigit, line)))
                    except:
                        score = -1
                if line.startswith("Ø¯Ù„ÛŒÙ„"):
                    reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()

            if reason == "ØªÙˆØ¶ÛŒØ­ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª":
                for i, line in enumerate(lines):
                    if "Ø§Ù…ØªÛŒØ§Ø²" in line and i + 1 < len(lines):
                        possible_reason = lines[i + 1]
                        if not possible_reason.startswith("Ø§Ù…ØªÛŒØ§Ø²") and "Ø¯Ù„ÛŒÙ„" not in possible_reason:
                            reason = possible_reason
                            break

            return {"title": job["title"], "score": score, "reason": reason}

        except Exception as e:
            return None

    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_job = {
            executor.submit(evaluate_job_with_key, api_key, job): job
            for api_key, job in zip(API_KEYS * (len(job_profiles) // len(API_KEYS) + 1), job_profiles)
        }

        for future in concurrent.futures.as_completed(future_to_job):
            result = future.result()
            if result:
                log_messages.append(f"ğŸ”¹ {result['title']} â†’ Ø§Ù…ØªÛŒØ§Ø²: {result['score']} | Ø¯Ù„ÛŒÙ„: {result['reason']}")
                if result["score"] > best_score:
                    best_score = result["score"]
                    best_match = result["title"]
                    best_reason = result["reason"]

    log = "\n".join(log_messages)

    if best_score >= threshold:
        return best_match, best_reason, log
    else:
        return "Ù…Ù†Ø§Ø³Ø¨ Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù… Ø§Ø² Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯", best_reason or "Ø±Ø²ÙˆÙ…Ù‡ ØªØ·Ø§Ø¨Ù‚ Ú©Ø§ÙÛŒ Ø¨Ø§ Ù‡ÛŒÚ†â€ŒÚ©Ø¯Ø§Ù… Ø§Ø² Ø´ØºÙ„â€ŒÙ‡Ø§ Ù†Ø¯Ø§Ø±Ø¯.", log


def apply_matching_to_batch(batch_df):
    all_results = []

    for idx, row in batch_df.iterrows():
        resume_text = " ".join([str(row[col]) for col in batch_df.columns])
        match_df = evaluate_resume_against_all_jobs(resume_text, JOB_PROFILES)

        match_df["Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡"] = idx + 1
        match_df["Ù†Ø§Ù…"] = row.get("Ù†Ø§Ù…", "")
        match_df["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"] = row.get("Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ", "")

        all_results.append(match_df)

    final_df = pd.concat(all_results, ignore_index=True)
    return final_df

top_universities = ['Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø´Ø±ÛŒÙ', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù†', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ±', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª Ø§ÛŒØ±Ø§Ù†']
public_keywords = ['ØµÙ†Ø¹ØªÛŒ', 'ØªÙ‡Ø±Ø§Ù†', 'Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ±', 'Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª', 'ÙØ±Ø¯ÙˆØ³ÛŒ', 'ØªØ¨Ø±ÛŒØ²', 'Ø§ØµÙÙ‡Ø§Ù†', 'Ø¯ÙˆÙ„ØªÛŒ']

def is_public_university(univ_name):
    return any(keyword in str(univ_name) for keyword in public_keywords)

def is_top_university(univ_name):
    return any(top in str(univ_name) for top in top_universities)

def color_score_column(val):
    if val >= 9:
        color = '#00C853'
    elif val >= 8:
        color = '#AEEA00'
    elif val >= 7:
        color = '#FFD600'
    elif val >= 6:
        color = '#FF9100'
    elif val >= 5:
        color = '#FF3D00'
    else:
        color = '#D50000'
    return f'background-color: {color}; color: white; font-weight: bold'


def adjust_score(row):
    score = row['score']
    if 'Ø³Ù†' in row and (row['Ø³Ù†'] < 22 or row['Ø³Ù†'] > 35):
        score -= 1
    if 'Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ' in row and (row['Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ'] < 20 or row['Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ'] > 45):
        score -= 1
    if 'Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ' in row and 'Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ' not in str(row['Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ']):
        score -= 0.5
    univ = row.get('Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡', '')
    if is_public_university(univ):
        score += 0.5
    if is_top_university(univ):
        score += 0.5
    return max(min(score, 10), 1.0)

def skill_agent(resume, skills):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: {', '.join(skills)}
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}
    
    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

skill_tool = Tool(
    name="SkillAgent",
    func=lambda input: skill_agent(input["resume"], input["skills"]),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ"
)
experience_tool = Tool(
    name="ExperienceAgent",
    func=lambda input: experience_agent(input["resume"], input["required_experience_desc"]),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ø´ØºÙ„ÛŒ"
)
education_tool = Tool(
    name="EducationAgent",
    func=lambda input: education_agent(
        input["resume"],
        input["university_list"],
        input["major_list"],
        input["job_profile_title"]
    ),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ­ØµÛŒÙ„Ø§Øª Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ"
)
volunteering_tool = Tool(
    name="VolunteeringAgent",
    func=lambda input: volunteering_agent(input["resume"], input.get("volunteering_field")),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡"
)
softskills_tool = Tool(
    name="SoftSkillsAgent",
    func=lambda input: softskills_agent(input["resume"], input.get("about_me_field")),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ùˆ Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ ÙØ±Ø¯ÛŒ"
)

def experience_agent(resume, required_experience_desc):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø§Ø² Ù†Ø¸Ø± Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø²ÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ø³Ø§Ø¨Ù‚Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: {required_experience_desc}
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}
    
    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø³Ø§Ø¨Ù‚Ù‡ Ú©Ø§Ø±ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason


def education_agent(resume, universities_info, major_list, job_profile_title):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø®Ø´ ØªØ­ØµÛŒÙ„Ø§Øª Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ ÙÙ‚Ø· Ø§Ø² Ù†Ø¸Ø± Ø³Ù‡ Ù…Ø¹ÛŒØ§Ø± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Û±. Ø§Ø¹ØªØ¨Ø§Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ùˆ Ù†ÙˆØ¹ Ø¢Ù† (Ø¯Ø± ÙÙ‡Ø±Ø³Øª Ø²ÛŒØ± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ùˆ Ù†ÙˆØ¹ Ù‡Ø±Ú©Ø¯Ø§Ù… Ø¢Ù…Ø¯Ù‡ Ø§Ø³ØªØŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± Ùˆ Ø¯ÙˆÙ„ØªÛŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¢Ø²Ø§Ø¯ Ùˆ Ù¾ÛŒØ§Ù… Ù†ÙˆØ± Ø§Ù…ØªÛŒØ§Ø² Ù…ØªÙˆØ³Ø·ØŒ ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±):
    {chr(10).join(universities_info)}
    Û². ØªØ·Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ "{job_profile_title}" (Ù„ÛŒØ³Øª Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø·Ù„ÙˆØ¨: {', '.join(major_list)})
    Û³. Ù…Ø¯Øª Ø²Ù…Ø§Ù† ØªØ­ØµÛŒÙ„ Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ (Ø²ÛŒØ± Û´ Ø³Ø§Ù„ Ø¹Ø§Ù„ÛŒØŒ Û´ Ø³Ø§Ù„ Ø®ÙˆØ¨ØŒ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û´ Ø³Ø§Ù„ Ø¶Ø¹ÛŒÙ)
    
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ ØªØ­ØµÛŒÙ„Ø§Øª Ø±Ø²ÙˆÙ…Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def volunteering_agent(resume, volunteering_field=None):
    field = volunteering_field if volunteering_field else resume
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ùˆ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ø§Ú¯Ø± ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ù…Ø±ØªØ¨Ø· Ùˆ ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø± (Ø¯Ø± Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§) Ø¨Ø§Ø´Ø¯ØŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ø¯Ù‡ØŒ Ø§Ú¯Ø± Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ú©Ù… Ø¨Ø§Ø´Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†.
    Ø±Ø²ÙˆÙ…Ù‡/ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡:
    {field}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def softskills_agent(resume, about_me_field=None):
    field = about_me_field if about_me_field else resume
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ùˆ Ø´Ø§ÛŒØ³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ±Ø¯ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„: Ú©Ø§Ø± ØªÛŒÙ…ÛŒØŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙˆØ«Ø±ØŒ Ù…Ø¯ÛŒØ±ÛŒØªØŒ Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ¾Ø°ÛŒØ±ÛŒØŒ Ø¯Ù‚ØªØŒ Ù…ÛŒÙ„ Ø¨Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ù‡ÙˆØ´ Ù‡ÛŒØ¬Ø§Ù†ÛŒ (EQ) Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†.
    Ø§Ú¯Ø± Ø±Ø²ÙˆÙ…Ù‡ ÛŒØ§ Ø¨Ø®Ø´ 'Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†' Ø´ÙˆØ§Ù‡Ø¯ Ù‚ÙˆÛŒ Ø§Ø² Ø§ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø§Ø±Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ø¯Ù‡ØŒ Ø§Ú¯Ø± Ù†Ø¯Ø§Ø´Øª ÛŒØ§ Ø¶Ø¹ÛŒÙ Ø¨ÙˆØ¯ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†.
    Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„:
    {field}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def scoring_chain(
    resume,
    skills,
    required_experience_desc,
    universities_info,
    major_list,
    job_profile_title,
    volunteering_field=None,
    about_me_field=None
):
    results = {}

    skill_score, skill_reason = skill_agent(resume, skills)
    results["SkillAgent"] = {"score": skill_score, "reason": skill_reason}

    exp_score, exp_reason = experience_agent(resume, required_experience_desc)
    results["ExperienceAgent"] = {"score": exp_score, "reason": exp_reason}

    edu_score, edu_reason = education_agent(resume, universities_info, major_list, job_profile_title)
    results["EducationAgent"] = {"score": edu_score, "reason": edu_reason}

    vol_score, vol_reason = volunteering_agent(resume, volunteering_field)
    results["VolunteeringAgent"] = {"score": vol_score, "reason": vol_reason}

    soft_score, soft_reason = softskills_agent(resume, about_me_field)
    results["SoftSkillsAgent"] = {"score": soft_score, "reason": soft_reason}

    results["VolunteeringAgent"]["score"] = score_text_section(vol_reason)
    results["SoftSkillsAgent"]["score"] = score_text_section(soft_reason)

    final_score = 0
    for agent, w in AGENT_WEIGHTS.items():
        final_score += results[agent]["score"] * w

    final_score = round(final_score / sum(AGENT_WEIGHTS.values()), 2)
    results["FinalScore"] = final_score

    return results


def evaluate_resume_against_all_jobs(resume_text, job_profiles):
    prompt = f"""Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÛŒÚ© Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒØ´Ø¯Ù‡ØŒ ÛŒÚ© Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ ÛŒÚ© Ø¯Ù„ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ø°Ú©Ø± Ú©Ù†ÛŒØ¯.

Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
[
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø§ÙˆÙ„",
    "match_percent": 85,
    "reason": "ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚ ÛŒØ§ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚"
  }},
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø¯ÙˆÙ…",
    "match_percent": 45,
    "reason": "..."
  }}
  ...
]
Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ:
{json.dumps(job_profiles, ensure_ascii=False)}
"""

    try:
        response = safe_generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0
            }
        )
        json_text = response.candidates[0].content.parts[0].text.strip()
        parsed = json.loads(json_text)
        return pd.DataFrame(parsed)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚: {e}")
        return pd.DataFrame()

def process_resume_row(row, row_index):
    resume_text = " ".join([str(row[col]) for col in row.index])
    title, reason, log = match_resume_to_job(resume_text, JOB_PROFILES)

    gemini_df = process_batch(pd.DataFrame([row]), prompt_text="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø±Ø²ÙˆÙ…Ù‡")
    initial_score = gemini_df.iloc[0]['score']

    score = adjust_score({**row.to_dict(), 'score': initial_score})

    new_data = row.to_dict()
    new_data.update({
        "Ø±Ø¯ÛŒÙ": row_index + 1,
        "score": score,
        "Ø¯Ù„ÛŒÙ„": gemini_df.iloc[0]['why'],
        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": title,
        "Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ": reason,
        "Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§": log
    })

    if RESULT_FILE_PATH.exists():
        existing = pd.read_excel(RESULT_FILE_PATH)
        updated = pd.concat([existing, pd.DataFrame([new_data])], ignore_index=True)
    else:
        updated = pd.DataFrame([new_data])

    updated.to_excel(RESULT_FILE_PATH, index=False)

    st.session_state['live_results'].append(new_data)
    return new_data

st.markdown("""
    <style>
    .custom-title {
        font-size: 50px !important;
        color: #1a73e8 !important;
        font-weight: bold !important;
        text-align: center !important;
        margin-top: 40px !important;
        margin-bottom: 30px !important;
    }
    </style>
""", unsafe_allow_html=True)
st.markdown('<div class="custom-title">ğŸ“‹ Ø³Ø§Ù…Ø§Ù†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø²ÙˆÙ…Ù‡</div>', unsafe_allow_html=True)
st.markdown("<p style='font-size: 16px; color: #555;'>Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒØŒ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ùˆ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ.</p>", unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“„ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯:", type=["xlsx"])

with st.sidebar:
    st.markdown("## ğŸ“Š ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…")
    st.markdown("### â³ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§")
    status_placeholder = st.empty()
    progress_placeholder = st.empty()

if uploaded_file and ('live_results' not in st.session_state or len(st.session_state['live_results']) == 0):
    status_placeholder.info("âœ… ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡. Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ...")
    progress_placeholder.progress(0)
elif not uploaded_file:
    status_placeholder.info("â³ Ù…Ù†ØªØ¸Ø± Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§Ø´ÛŒØ¯.")
    progress_placeholder.progress(0)

with st.sidebar:
    if st.button("ğŸ”„ Ø±ÛŒØ³Øª Ú©Ø§Ù…Ù„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª"):
        for key in ['final_df', 'live_results']:
            if key in st.session_state:
                del st.session_state[key]
        if RESULT_FILE_PATH.exists():
            RESULT_FILE_PATH.unlink()
        st.success("âœ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±ÛŒØ³Øª Ø´Ø¯.")

job_titles = [job['title'] for job in JOB_PROFILES]

selected_job_titles = st.multiselect(
    "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ (Ø§Ù…Ú©Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ Ú†Ù†Ø¯ØªØ§ÛŒÛŒ):",
    options=job_titles,
    default=None
)

custom_job_title = st.text_input("Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø´Ù…Ø§ Ø¯Ø± Ù„ÛŒØ³Øª Ù†Ø¨ÙˆØ¯ØŒ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

all_selected_titles = selected_job_titles.copy()
if custom_job_title.strip() != "":
    all_selected_titles.append(custom_job_title.strip())

selected_skills = []
for job in JOB_PROFILES:
    if job["title"] in all_selected_titles:
        selected_skills.extend([c['name'] for c in job.get('competencies_technical', [])])

selected_skills = list(sorted(set(selected_skills)))

edited_skills = st.multiselect(
    "Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯:",
    options=selected_skills,
    default=selected_skills
)

custom_skill = st.text_input("Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ù…Ù‡Ø§Ø±Øª Ø¬Ø¯ÛŒØ¯ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

all_skills = edited_skills.copy()
if custom_skill.strip() and custom_skill.strip() not in all_skills:
    all_skills.append(custom_skill.strip())

def process_single_resume(args):
    """Process a single resume with a specific API key"""
    idx, row, api_key, all_skills = args
    start_time = time.time()
    
    try:
        llm_instance = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
        
        resume = " ".join([str(row[col]) for col in row.index]) 
        required_experience_desc = "Ø³Ø§Ø¨Ù‚Ù‡ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ" 
        universities = universities_info 
        major_list = []
        job_profile_title = ""
        volunteering_field = row.get("ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡", "") 
        about_me_field = row.get("Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†", "")

        results = scoring_chain(
            resume, 
            all_skills, 
            required_experience_desc, 
            universities, 
            major_list, 
            job_profile_title, 
            volunteering_field, 
            about_me_field
        )

        row_data = row.to_dict()
        row_data['Ø±Ø¯ÛŒÙ'] = idx + 1
        for agent, detail in results.items():
            if agent != "FinalScore":
                row_data[f"{agent}_score"] = detail['score']
                row_data[f"{agent}_reason"] = detail['reason']
        row_data['final_score'] = results['FinalScore']
        row_data['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] = "ØªØ§ÛŒÛŒØ¯" if row_data['final_score'] >= 70 else "Ø±Ø¯"

        processing_time = round(time.time() - start_time, 2)
        row_data['Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø«Ø§Ù†ÛŒÙ‡)'] = processing_time 
        
        return (idx, row_data, None)
    
    except Exception as e:
        processing_time = round(time.time() - start_time, 2)
        return (idx, None, str(e))

if uploaded_file:
    df = pd.read_excel(uploaded_file, skiprows=2)
    
    st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡: {len(df)} | ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {len(df.columns)}")
    
    with st.expander("Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"):
        st.dataframe(df.head())
    
    stage = st.radio("ğŸ§© Ù…Ø±Ø­Ù„Ù‡ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", ["Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ", "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"])

    if stage == "Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ": 
        st.markdown("### ğŸš€ Ù…Ø±Ø­Ù„Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§") 
        
        max_workers = min(len(API_KEYS), len(df))
        st.info(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ {max_workers} API Key Ø¨Ø±Ø§ÛŒ {len(df)} Ø±Ø²ÙˆÙ…Ù‡")
        
        if st.button("Ø´Ø±ÙˆØ¹ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ"): 
            total_start_time = time.time()
            results_placeholder = st.empty() 
            progress_bar = st.progress(0) 
            rows = [None] * len(df)
            completed = 0
            
            processing_args = [
                (idx, row, API_KEYS[idx % len(API_KEYS)], all_skills)
                for idx, (_, row) in enumerate(df.iterrows())
            ]
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_idx = {
                    executor.submit(process_single_resume, args): args[0] 
                    for args in processing_args
                }
                
                for future in concurrent.futures.as_completed(future_to_idx):
                    idx, row_data, error = future.result()
                    
                    if error:
                        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø²ÙˆÙ…Ù‡ Ø±Ø¯ÛŒÙ {idx + 1}: {error}")
                        row_data = df.iloc[idx].to_dict()
                        row_data['Ø±Ø¯ÛŒÙ'] = idx + 1
                        row_data['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] = "Ø®Ø·Ø§"
                        row_data['final_score'] = 0
                    
                    rows[idx] = row_data
                    completed += 1
                    
                    progress_bar.progress(completed / len(df))
                    
                    current_results = [r for r in rows if r is not None]
                    if current_results:
                        temp_df = pd.DataFrame(current_results)
                        results_placeholder.dataframe(temp_df)
                    
                    live_df = pd.DataFrame(current_results)
                    total = len(df)
                    checked = len(live_df)
                    accepted = (live_df['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] == 'ØªØ§ÛŒÛŒØ¯').sum() if 'ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡' in live_df.columns else 0
                    failed = (live_df['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] != 'ØªØ§ÛŒÛŒØ¯').sum() if 'ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡' in live_df.columns else 0
                    
                     if 'Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø«Ø§Ù†ÛŒÙ‡)' in live_df.columns:
                        avg_time = live_df['Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø«Ø§Ù†ÛŒÙ‡)'].mean()
                        estimated_remaining = avg_time * (total - checked)
                        status_placeholder.markdown(f"""
                        **Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {checked} / {total}**  
                        ğŸŸ¢ Ù‚Ø¨ÙˆÙ„â€ŒØ´Ø¯Ù‡: {accepted}  
                        ğŸ”´ Ø±Ø¯â€ŒØ´Ø¯Ù‡: {failed}  
                        â±ï¸ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ù‡Ø± Ø±Ø²ÙˆÙ…Ù‡: {avg_time:.2f}s  
                        â³ ØªØ®Ù…ÛŒÙ† Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡: {estimated_remaining:.1f}s ({estimated_remaining/60:.1f} Ø¯Ù‚ÛŒÙ‚Ù‡)
                        """)
                    else:
                        status_placeholder.success(f"Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {checked} / {total}")
                        status_placeholder.markdown(f"ğŸŸ¢ Ù‚Ø¨ÙˆÙ„â€ŒØ´Ø¯Ù‡: {accepted}")
                        status_placeholder.markdown(f"ğŸ”´ Ø±Ø¯â€ŒØ´Ø¯Ù‡: {failed}")
                    progress_placeholder.progress(checked / total)
            
            results_df = pd.DataFrame(rows)
            results_placeholder.dataframe(results_df)
            results_df.to_excel("resume_scoring.xlsx", index=False)
            style_excel("resume_scoring.xlsx")

            total_time = round(time.time() - total_start_time, 2)  
            st.success(f"âœ… Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø²Ù…Ø§Ù† Ú©Ù„: {total_time} Ø«Ø§Ù†ÛŒÙ‡ ({total_time/60:.2f} Ø¯Ù‚ÛŒÙ‚Ù‡)")

            with open("resume_scoring.xlsx", "rb") as f:
                st.download_button(
                    label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ",
                    data=f,
                    file_name="resume_scoring.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    elif stage == "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ":
        st.markdown("### ğŸ” Ù…Ø±Ø­Ù„Ù‡ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ")
        results_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        max_workers = min(len(API_KEYS), len(df))
        st.info(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ {max_workers} API Key Ø¨Ø±Ø§ÛŒ {len(df)} Ø±Ø²ÙˆÙ…Ù‡")

        if st.button("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"):
            total_start_time = time.time() 
            try:
                def process_single_matching(args):
                    """Process job matching for a single resume"""
                    idx, row, api_key = args
                    start_time = time.time()
                    try:
                        resume_text = " ".join([str(row[col]) for col in row.index])
                        
                        prompt = f"""Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÛŒÚ© Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒØ´Ø¯Ù‡ØŒ ÛŒÚ© Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ ÛŒÚ© Ø¯Ù„ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ø°Ú©Ø± Ú©Ù†ÛŒØ¯.

Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
[
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø§ÙˆÙ„",
    "match_percent": 85,
    "reason": "ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚ ÛŒØ§ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚"
  }},
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø¯ÙˆÙ…",
    "match_percent": 45,
    "reason": "..."
  }}
  ...
]
Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ:
{json.dumps(JOB_PROFILES, ensure_ascii=False)}
"""
                        
                        client = genai.Client(api_key=api_key)
                        response = client.models.generate_content(
                            model="gemini-2.5-flash",
                            contents=prompt,
                            config={
                                "response_mime_type": "application/json",
                                "temperature": 0
                            }
                        )
                        
                        json_text = response.candidates[0].content.parts[0].text.strip()
                        parsed = json.loads(json_text)
                        match_df = pd.DataFrame(parsed)
                        
                        match_df["Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡"] = idx + 1
                        match_df["Ù†Ø§Ù…"] = row.get("Ù†Ø§Ù…", "")
                        match_df["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"] = row.get("Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ", "")
                        processing_time = round(time.time() - start_time, 2)  # ADD THIS LINE
                        match_df["Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ (Ø«Ø§Ù†ÛŒÙ‡)"] = processing_time

                        return (idx, match_df, None)
                    except Exception as e:
                        return (idx, None, str(e))
                
                processing_args = [
                    (idx, row, API_KEYS[idx % len(API_KEYS)])
                    for idx, (_, row) in enumerate(df.iterrows())
                ]
                
                all_results = [None] * len(df)
                completed = 0
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_idx = {
                        executor.submit(process_single_matching, args): args[0]
                        for args in processing_args
                    }
                    
                    for future in concurrent.futures.as_completed(future_to_idx):
                        idx, match_df, error = future.result()
                        
                        if error:
                            st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ·Ø¨ÛŒÙ‚ Ø±Ø²ÙˆÙ…Ù‡ Ø±Ø¯ÛŒÙ {idx + 1}: {error}")
                        else:
                            all_results[idx] = match_df
                        
                        completed += 1
                        progress_bar.progress(completed / len(df))
                
                match_results = pd.concat([r for r in all_results if r is not None], ignore_index=True)
                
                def make_sentence(row):
                    return f"Ù…ÛŒØ²Ø§Ù† Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ {row['title']} {int(row['match_percent'])}Ùª Ø§Ø³ØªØŒ Ø²ÛŒØ±Ø§: {row['reason']}"

                grouped = match_results.groupby("Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡")

                final_rows = []
                for resume_row_num, group in grouped:
                    name = group["Ù†Ø§Ù…"].iloc[0]
                    family = group["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"].iloc[0]
                    sentences = [make_sentence(row) for _, row in group.iterrows()]
                    full_text = "  ".join(sentences)
                    best_row = group.loc[group["match_percent"].idxmax()]
                    best_title = best_row["title"]

                    final_rows.append({
                        "Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡": resume_row_num,
                        "Ù†Ø§Ù…": name,
                        "Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ": family,
                        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": best_title,
                        "ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ": full_text
                    })

                summary_df = pd.DataFrame(final_rows)

                summary_path = "job_matching_summary.xlsx"
                summary_df.to_excel(summary_path, index=False)
                style_excel(summary_path)
                total_time = round(time.time() - total_start_time, 2)  # ADD THIS LINE
                st.success(f"âœ… ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ø²Ù…Ø§Ù† Ú©Ù„: {total_time} Ø«Ø§Ù†ÛŒÙ‡ ({total_time/60:.2f} Ø¯Ù‚ÛŒÙ‚Ù‡)")
                st.dataframe(summary_df)

                with open(summary_path, "rb") as f:
                    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ØªØ­Ù„ÛŒÙ„â€ŒØ´Ø¯Ù‡", f, file_name=summary_path)

                progress_bar.progress(1.0)
            
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ØªØ·Ø¨ÛŒÙ‚: {e}")

if RESULT_FILE_PATH.exists():
    final_df = pd.read_excel(RESULT_FILE_PATH)

    display_df = final_df.copy()
    display_df.index = display_df.index + 1
    display_df.index.name = "Ø±Ø¯ÛŒÙ"

    st.markdown("### âœ… Ø¬Ø¯ÙˆÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒØ´Ø¯Ù‡")
    
    if 'score' in display_df.columns:
        styled_df = display_df.style.applymap(color_score_column, subset=['score'])
        st.dataframe(styled_df)
    else:
        st.dataframe(display_df)

    style_excel(RESULT_FILE_PATH)
    with open(RESULT_FILE_PATH, "rb") as f:
        st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ", f, file_name="resume_results.xlsx")



