# ØªØºÛŒÛŒØ±Ø§Øª Ù„Ø§Ø²Ù… Ø¯Ø± app.py Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø³ØªÙˆÙ† "Ø´Ù†Ø§Ø³Ù‡"

import pandas as pd
import json
import time
from sklearn.preprocessing import MinMaxScaler
import ssl
import certifi
from google import genai
import streamlit as st
from io import BytesIO
from pathlib import Path
import requests
import os
import concurrent.futures
from langchain.agents import Tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import openpyxl
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
import base64

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ
pd.set_option('display.max_rows', None)
OUTPUT_ALL_PATH = Path("recruitment_score.xlsx")

# **ØªØºÛŒÛŒØ± Ù…Ù‡Ù…: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡**
# ID_COLUMN = 'Ø´Ù†Ø§Ø³Ù‡'  # Ø­Ø°Ù Ø§ÛŒÙ† Ø®Ø·
BATCH_SIZE = 10
RESULT_FILE_PATH = Path("resume_results.xlsx")

# Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯ Ù‡Ù…Ø§Ù† Ú©Ø¯Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ...
API_KEYS = [
    "AIzaSyAQ1Z8HmIZm-eNvohxoM4ZNFM8JsZsxDII",
    "AIzaSyAQhK01WbSxiXUdXqe5xEvJA3feUiQCL0E",
    # ... Ø³Ø§ÛŒØ± Ú©Ù„ÛŒØ¯Ù‡Ø§
]

# ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§
def generate_unique_id(row_index, row_data):
    """ØªÙˆÙ„ÛŒØ¯ Ø´Ù†Ø§Ø³Ù‡ ÛŒÚ©ØªØ§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ø¯ÛŒÙ"""
    # Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³
    if 'Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³' in row_data and row_data['Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³']:
        return str(row_data['Ø´Ù…Ø§Ø±Ù‡ ØªÙ…Ø§Ø³'])
    
    # Ø§ÙˆÙ„ÙˆÛŒØª Ø¯ÙˆÙ…: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ±Ú©ÛŒØ¨ Ù†Ø§Ù… Ùˆ Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ
    if 'Ù†Ø§Ù…' in row_data and 'Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ' in row_data:
        name_combo = f"{row_data['Ù†Ø§Ù…']}_{row_data['Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ']}"
        return name_combo.replace(' ', '_')
    
    # Ø§ÙˆÙ„ÙˆÛŒØª Ø³ÙˆÙ…: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ…ÛŒÙ„
    if 'Ø§ÛŒÙ…ÛŒÙ„' in row_data and row_data['Ø§ÛŒÙ…ÛŒÙ„']:
        return str(row_data['Ø§ÛŒÙ…ÛŒÙ„']).split('@')[0]
    
    # Ø§ÙˆÙ„ÙˆÛŒØª Ú†Ù‡Ø§Ø±Ù…: Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø±Ø¯ÛŒÙ
    return f"ROW_{row_index}"

def get_row_id(row, row_index):
    """Ø¯Ø±ÛŒØ§ÙØª Ø´Ù†Ø§Ø³Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø±Ø¯ÛŒÙ"""
    # Ø§Ú¯Ø± Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    if 'Ø´Ù†Ø§Ø³Ù‡' in row and row['Ø´Ù†Ø§Ø³Ù‡']:
        return str(row['Ø´Ù†Ø§Ø³Ù‡'])
    
    # Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø´Ù†Ø§Ø³Ù‡ Ø¬Ø¯ÛŒØ¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ù†
    return generate_unique_id(row_index, row)

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ batch
def process_batch(batch_df, prompt_text):
    payload = {
        "employer requirements": prompt_text,
        "applicant information": []
    }
    
    for idx, (_, row) in enumerate(batch_df.iterrows()):
        resume_text = " ".join([str(row[col]) for col in batch_df.columns])
        row_id = get_row_id(row, idx)
        
        payload["applicant information"].append({
            "resume": resume_text, 
            "id": row_id
        })
    
    try:
        response = safe_generate_content(
            model='gemini-2.5-flash',
            contents=json.dumps(payload, ensure_ascii=False),
            config={
                'response_mime_type': 'application/json',
                'system_instruction': """
Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:
- ØªØ·Ø§Ø¨Ù‚ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ
- ØªØ·Ø§Ø¨Ù‚ Ø³ÙˆØ§Ø¨Ù‚ Ø´ØºÙ„ÛŒ
- Ù…Ù‚Ø·Ø¹ Ùˆ Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ Ù…Ø±ØªØ¨Ø·
- Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¯ÙˆÙ„ØªÛŒ Ùˆ Ù…Ø¹ØªØ¨Ø±
- Ø³Ù† Ù…Ù†Ø§Ø³Ø¨ (Û²Û² ØªØ§ Û³Ûµ)
- Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ (Û²Û° ØªØ§ Û´Ûµ Ù…ÛŒÙ„ÛŒÙˆÙ†)
Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† Û± ØªØ§ Û±Û° Ø¨Ø¯Ù‡ÛŒØ¯. Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯: 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª'.
""",
                'response_schema': {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "score": {"type": "number", "nullable": False},
                            "check_id": {"type": "string", "nullable": False},
                            "why": {"type": "string", "nullable": False}
                        }
                    }
                },
                'temperature': 0
            }
        )
        result = json.loads(response.candidates[0].content.parts[0].text)
        return pd.DataFrame(result)
    except Exception:
        # Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ Ù¾Ø§Ø³Ø® Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø¯Ù‡
        default_results = []
        for idx, (_, row) in enumerate(batch_df.iterrows()):
            row_id = get_row_id(row, idx)
            default_results.append({
                "score": 1.0,
                "check_id": row_id,
                "why": "Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª"
            })
        return pd.DataFrame(default_results)

def apply_matching_to_batch(batch_df):
    all_results = []
    
    for idx, (_, row) in enumerate(batch_df.iterrows()):
        resume_text = " ".join([str(row[col]) for col in batch_df.columns])
        match_df = evaluate_resume_against_all_jobs(resume_text, JOB_PROFILES)
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ù‡
        row_id = get_row_id(row, idx)
        match_df["Ø´Ù†Ø§Ø³Ù‡ Ø±Ø²ÙˆÙ…Ù‡"] = row_id
        match_df["Ù†Ø§Ù…"] = row.get("Ù†Ø§Ù…", "")
        match_df["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"] = row.get("Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ", "")
        
        all_results.append(match_df)
    
    return pd.concat(all_results, ignore_index=True)

def process_resume_row(row, row_index):
    resume_text = " ".join([str(row[col]) for col in row.index])
    title, reason, log = match_resume_to_job(resume_text, JOB_PROFILES)
    
    # Ú¯Ø±ÙØªÙ† Ø§Ù…ØªÛŒØ§Ø² Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø² Gemini
    gemini_df = process_batch(pd.DataFrame([row]), prompt_text="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø±Ø²ÙˆÙ…Ù‡")
    initial_score = gemini_df.iloc[0]['score']
    
    # Ø§ØµÙ„Ø§Ø­ Ø§Ù…ØªÛŒØ§Ø²
    score = adjust_score({**row.to_dict(), 'score': initial_score})
    
    # Ø´Ù†Ø§Ø³Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø±Ø¯ÛŒÙ
    row_id = get_row_id(row, row_index)
    
    new_data = row.to_dict()
    new_data.update({
        "Ø´Ù†Ø§Ø³Ù‡": row_id,  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø´Ù†Ø§Ø³Ù‡ Ø¨Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        "score": score,
        "Ø¯Ù„ÛŒÙ„": gemini_df.iloc[0]['why'],
        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": title,
        "Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ": reason,
        "Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§": log
    })
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
    if RESULT_FILE_PATH.exists():
        existing = pd.read_excel(RESULT_FILE_PATH)
        updated = pd.concat([existing, pd.DataFrame([new_data])], ignore_index=True)
    else:
        updated = pd.DataFrame([new_data])
    
    updated.to_excel(RESULT_FILE_PATH, index=False)
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± session
    if 'live_results' not in st.session_state:
        st.session_state['live_results'] = []
    st.session_state['live_results'].append(new_data)
    
    return new_data

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª done_ids
def get_done_ids():
    """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø´Ù†Ø§Ø³Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡"""
    if RESULT_FILE_PATH.exists():
        existing_df = pd.read_excel(RESULT_FILE_PATH)
        if 'Ø´Ù†Ø§Ø³Ù‡' in existing_df.columns:
            return existing_df['Ø´Ù†Ø§Ø³Ù‡'].tolist()
        else:
            # Ø§Ú¯Ø± Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            return [f"ROW_{i}" for i in existing_df.index]
    return []

# Ø¨Ø®Ø´ Ø§ØµÙ„ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªØºÛŒÛŒØ± Ø¯Ø§Ø±Ø¯
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    
    stage = st.radio("ğŸ§© Ù…Ø±Ø­Ù„Ù‡ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", ["Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ", "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"])
    done_ids = get_done_ids()  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªØ§Ø¨Ø¹ Ø¬Ø¯ÛŒØ¯

    if stage == "Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ": 
        st.markdown("### ğŸš€ Ù…Ø±Ø­Ù„Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§") 
        if st.button("Ø´Ø±ÙˆØ¹ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ"): 
            results_placeholder = st.empty() 
            progress_bar = st.progress(0) 
            rows = [] 
            
            for idx, (_, row) in enumerate(df.iterrows()): 
                current_row_id = get_row_id(row, idx)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø±Ø¯ÛŒÙ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡
                if current_row_id in done_ids: 
                    continue

                resume = " ".join([str(row[col]) for col in row.index]) 
                skills = all_skills
                required_experience_desc = "Ø³Ø§Ø¨Ù‚Ù‡ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ" 
                universities = universities_info 
                major_list = []
                job_profile_title = ""
                volunteering_field = row.get("ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡", "") 
                about_me_field = row.get("Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†", "")

                results = scoring_chain(
                    resume, 
                    skills, 
                    required_experience_desc, 
                    universities, 
                    major_list, 
                    job_profile_title, 
                    volunteering_field, 
                    about_me_field
                )

                row_data = row.to_dict() 
                row_data['Ø´Ù†Ø§Ø³Ù‡'] = current_row_id  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø´Ù†Ø§Ø³Ù‡
                
                for agent, detail in results.items():
                    if agent != "FinalScore":
                        row_data[f"{agent}_score"] = detail['score']
                        row_data[f"{agent}_reason"] = detail['reason']
                row_data['final_score'] = results['FinalScore']

                row_data['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] = "ØªØ§ÛŒÛŒØ¯" if row_data['final_score'] >= 70 else "Ø±Ø¯"
                rows.append(row_data)

                progress_bar.progress((idx + 1) / len(df))

            # Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            results_df = pd.DataFrame(rows)
            results_placeholder.dataframe(results_df)
            results_df.to_excel("resume_scoring.xlsx", index=False)
            style_excel("resume_scoring.xlsx")

            st.success("âœ… Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
            
            with open("resume_scoring.xlsx", "rb") as f:
                st.download_button(
                    label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ",
                    data=f,
                    file_name="resume_scoring.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    elif stage == "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ":
        st.markdown("### ğŸ” Ù…Ø±Ø­Ù„Ù‡ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ")
        
        if st.button("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"):
            try:
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§
                match_results = apply_matching_to_batch(df.copy())
                
                # Ø³Ø§Ø®Øª Ø®Ø±ÙˆØ¬ÛŒ Ø®Ù„Ø§ØµÙ‡â€ŒØ´Ø¯Ù‡
                def make_sentence(row):
                    return f"Ù…ÛŒØ²Ø§Ù† Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ {row['title']} {int(row['match_percent'])}Ùª Ø§Ø³ØªØŒ Ø²ÛŒØ±Ø§: {row['reason']}"

                grouped = match_results.groupby("Ø´Ù†Ø§Ø³Ù‡ Ø±Ø²ÙˆÙ…Ù‡")
                final_rows = []
                
                for resume_id, group in grouped:
                    name = group["Ù†Ø§Ù…"].iloc[0]
                    family = group["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"].iloc[0]
                    sentences = [make_sentence(row) for _, row in group.iterrows()]
                    full_text = "  ".join(sentences)
                    best_row = group.loc[group["match_percent"].idxmax()]
                    best_title = best_row["title"]

                    final_rows.append({
                        "Ø´Ù†Ø§Ø³Ù‡ Ø±Ø²ÙˆÙ…Ù‡": resume_id,
                        "Ù†Ø§Ù…": name,
                        "Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ": family,
                        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": best_title,
                        "ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ": full_text
                    })

                summary_df = pd.DataFrame(final_rows)
                summary_path = "job_matching_summary.xlsx"
                summary_df.to_excel(summary_path, index=False)
                style_excel(summary_path)

                st.success("âœ… ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
                st.dataframe(summary_df)

                with open(summary_path, "rb") as f:
                    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ØªØ­Ù„ÛŒÙ„â€ŒØ´Ø¯Ù‡", f, file_name=summary_path)
            
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ØªØ·Ø¨ÛŒÙ‚: {e}")

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ
if RESULT_FILE_PATH.exists():
    final_df = pd.read_excel(RESULT_FILE_PATH)
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡
    if 'Ø´Ù†Ø§Ø³Ù‡' not in final_df.columns:
        final_df['Ø´Ù†Ø§Ø³Ù‡'] = [generate_unique_id(i, row) for i, (_, row) in enumerate(final_df.iterrows())]
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¬Ø¯Ø¯ ÙØ§ÛŒÙ„ Ø¨Ø§ Ø³ØªÙˆÙ† Ø´Ù†Ø§Ø³Ù‡
        final_df.to_excel(RESULT_FILE_PATH, index=False)

    display_df = final_df.copy()
    display_df.index = display_df.index + 1
    display_df.index.name = "Ø±Ø¯ÛŒÙ"

    st.markdown("### âœ… Ø¬Ø¯ÙˆÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒØ´Ø¯Ù‡")
    
    if 'score' in display_df.columns:
        styled_df = display_df.style.applymap(color_score_column, subset=['score'])
        st.dataframe(styled_df)
    else:
        st.dataframe(display_df)

    style_excel(RESULT_FILE_PATH)
    
    with open(RESULT_FILE_PATH, "rb") as f:
        st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ", f, file_name="resume_results.xlsx")
