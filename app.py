import pandas as pd
import json
import time
from sklearn.preprocessing import MinMaxScaler
import ssl
import certifi
from google import genai
import streamlit as st
from io import BytesIO
from pathlib import Path
import requests
import os
import concurrent.futures
from langchain.agents import Tool
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import openpyxl
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
import base64

API_KEYS = [
    "AIzaSyD09_gws5tBYZmD0YHF1etSZ7K-7wePIh0",
    "AIzaSyBJ2N1RHTTTQMXUod7jPymZwbgnPsdgLsY",
    "AIzaSyBwvI4kSZWOnWG3Km6kpUbqD87wIUVcoHs",
    "AIzaSyDKvI5lwfrihbcXXaXxaQWhGULE77afyrg",
    "AIzaSyCxpTPYFq91HfeUVqe8JD3RjiU4nV63WH8",
    "AIzaSyCWZVz-ciOp91vKr2u7J87IktK2skygOro",
    "AIzaSyB11u1-TTuvIRNhSAp44PgWWpoK9kq1mAo",
    "AIzaSyBxusefsMEbKv6HAoYxECpOIqbKO-pCs2g",
    "AIzaSyDIAYd4QdTBQO4MVOnAvoA5tNEozVYdflE",
    "AIzaSyBw6zUcIsp5t4QZxI_BRiPphYJzf7mq8p4",
    "AIzaSyC3EpZaqKLQwxCGUxKLzuwzvtKT2EjYTEA",
    "AIzaSyAkXdS9nAA35pdOX4kZQaFOgOznjU9MlDs",
    "AIzaSyBZqnpTMHL8Zap2CIrqifqXVA5YB30Apuw",
    "AIzaSyBqTtltNANsAhbodnxfFJOFq8vaGszJPqQ",
    "AIzaSyCC2RTsg8ArBgXj8t82-w-agFE82s0CUHw",
    "AIzaSyDvtLtNuVVlgNBvzwPRl42RyWZJqRsCI4Q",
    "AIzaSyATYlQN6L7SJz7mY7wScnyB8G_DqRsJQT4",
    "AIzaSyBW8Q1amjzs0_XLHaKaecyZuQJe0U5qhZU",
    "AIzaSyA7YtWUSsljlQuWOuy3fSBajot2rI5D3e8",
    "AIzaSyAsFagF5Z-A_o2pvUiAwpzqXpDpRNjhwfM",
    "AIzaSyDG8LTKH4NGqQcaGAz76z4hKAQ95jVjz4c",
    "AIzaSyDwB9W3SJjG5qkTd58L8ToX0xmi57Kh8d4",
    "AIzaSyBNAb6TSR4mhq82WtW2wHSCOUDK73IDbfs",
    "AIzaSyB51i5YnENFBE8aYncinPtwLk1dThl2CuA"
]
# Page Configuration
st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø²ÙˆÙ…Ù‡",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for Beautiful UI
def load_css():
    css = """
    <style>
    /* Import Google Font for Persian */
    @import url('https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;500;600;700&display=swap');
    
    /* Main Theme Colors */
    :root {
        --primary-color: #6C63FF;
        --secondary-color: #FF6B6B;
        --success-color: #4ECDC4;
        --warning-color: #FFD93D;
        --info-color: #74C0FC;
        --dark-bg: #1A1B3A;
        --light-bg: #F7F9FC;
        --card-bg: #FFFFFF;
        --text-dark: #2D3436;
        --text-light: #636E72;
    }
    
    /* Global Font and Direction */
    * {
        font-family: 'Vazirmatn', Tahoma, sans-serif !important;
        direction: rtl !important;
    }
    
    /* Main App Background */
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    
    /* Header Styling */
    .main-header {
        background: linear-gradient(135deg, #6C63FF 0%, #8B7FFF 100%);
        padding: 2rem;
        border-radius: 20px;
        box-shadow: 0 10px 40px rgba(0,0,0,0.1);
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    
    .main-title {
        font-size: 3.5rem;
        font-weight: 700;
        color: white;
        margin-bottom: 0.5rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .main-subtitle {
        font-size: 1.2rem;
        color: rgba(255,255,255,0.9);
        font-weight: 300;
    }
    
    /* Card Styles */
    .custom-card {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 5px 20px rgba(0,0,0,0.08);
        margin-bottom: 1.5rem;
        transition: all 0.3s ease;
        border: 1px solid rgba(255,255,255,0.1);
    }
    
    .custom-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 30px rgba(0,0,0,0.12);
    }
    
    .card-header {
        display: flex;
        align-items: center;
        margin-bottom: 1rem;
        padding-bottom: 0.8rem;
        border-bottom: 2px solid #f0f0f0;
    }
    
    .card-icon {
        font-size: 1.5rem;
        margin-left: 0.8rem;
    }
    
    .card-title {
        font-size: 1.3rem;
        font-weight: 600;
        color: var(--text-dark);
    }
    
    /* Stats Cards */
    .stats-card {
        background: linear-gradient(135deg, var(--primary-color) 0%, #8B7FFF 100%);
        border-radius: 15px;
        padding: 1.5rem;
        color: white;
        text-align: center;
        box-shadow: 0 5px 20px rgba(108, 99, 255, 0.3);
        transition: transform 0.3s ease;
    }
    
    .stats-card:hover {
        transform: scale(1.05);
    }
    
    .stats-number {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }
    
    .stats-label {
        font-size: 1rem;
        opacity: 0.9;
    }
    
    /* Button Styles */
    .stButton > button {
        background: linear-gradient(135deg, var(--primary-color) 0%, #8B7FFF 100%);
        color: white;
        border: none;
        padding: 0.75rem 2rem;
        font-size: 1.1rem;
        font-weight: 500;
        border-radius: 50px;
        box-shadow: 0 5px 20px rgba(108, 99, 255, 0.3);
        transition: all 0.3s ease;
        width: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 7px 25px rgba(108, 99, 255, 0.4);
    }
    
    /* Upload Area */
    .uploadedFile {
        background: white;
        border: 2px dashed var(--primary-color);
        border-radius: 15px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .uploadedFile:hover {
        border-color: var(--secondary-color);
        background: rgba(108, 99, 255, 0.05);
    }
    
    /* Progress Bar */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, var(--success-color) 0%, var(--primary-color) 100%);
        border-radius: 10px;
        height: 10px;
    }
    
    /* Sidebar Styling */
    .css-1d391kg {
        background: linear-gradient(180deg, var(--dark-bg) 0%, #2D3456 100%);
    }
    
    .sidebar-card {
        background: rgba(255,255,255,0.1);
        backdrop-filter: blur(10px);
        border-radius: 15px;
        padding: 1.5rem;
        margin-bottom: 1rem;
        border: 1px solid rgba(255,255,255,0.2);
        color: white;
    }
    
    /* Select Box and Input Styling */
    .stSelectbox > div > div, .stMultiSelect > div > div {
        background: white;
        border-radius: 10px;
        border: 2px solid #E0E0E0;
        transition: border-color 0.3s ease;
    }
    
    .stSelectbox > div > div:focus-within, .stMultiSelect > div > div:focus-within {
        border-color: var(--primary-color);
        box-shadow: 0 0 0 3px rgba(108, 99, 255, 0.1);
    }
    
    /* Tab Styling */
    .stTabs [data-baseweb="tab-list"] {
        background: white;
        border-radius: 15px;
        padding: 0.5rem;
        box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, var(--primary-color) 0%, #8B7FFF 100%);
        color: white !important;
    }
    
    /* Alert Boxes */
    .success-box {
        background: linear-gradient(135deg, #00C9A7 0%, #00D4AA 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0, 201, 167, 0.3);
    }
    
    .warning-box {
        background: linear-gradient(135deg, #FFB800 0%, #FFD93D 100%);
        color: var(--text-dark);
        padding: 1rem 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(255, 184, 0, 0.3);
    }
    
    .info-box {
        background: linear-gradient(135deg, #74C0FC 0%, #94D3FF 100%);
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(116, 192, 252, 0.3);
    }
    
    /* Metrics Display */
    [data-testid="metric-container"] {
        background: white;
        border-radius: 15px;
        padding: 1.5rem;
        box-shadow: 0 3px 15px rgba(0,0,0,0.08);
        border: 1px solid #f0f0f0;
        transition: all 0.3s ease;
    }
    
    [data-testid="metric-container"]:hover {
        transform: translateY(-3px);
        box-shadow: 0 5px 20px rgba(0,0,0,0.12);
    }
    
    /* Dataframe Styling */
    [data-testid="stDataFrame"] {
        background: white;
        border-radius: 15px;
        padding: 1rem;
        box-shadow: 0 3px 15px rgba(0,0,0,0.08);
    }
    
    /* Expander Styling */
    .streamlit-expanderHeader {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .streamlit-expanderHeader:hover {
        background: linear-gradient(135deg, #e9ecef 0%, #adb5bd 100%);
    }
    
    /* Loading Animation */
    @keyframes pulse {
        0% { transform: scale(1); opacity: 1; }
        50% { transform: scale(1.05); opacity: 0.8; }
        100% { transform: scale(1); opacity: 1; }
    }
    
    .loading {
        animation: pulse 2s infinite;
    }
    
    /* Responsive Design */
    @media (max-width: 768px) {
        .main-title { font-size: 2.5rem; }
        .stats-number { font-size: 2rem; }
        .custom-card { padding: 1rem; }
    }
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)

def load_font_css():
    font_regular = None
    font_bold = None
    
    if os.path.exists("0 Nazanin.TTF"):
        with open("0 Nazanin.TTF", "rb") as f:
            font_regular = base64.b64encode(f.read()).decode()
    
    if os.path.exists("0 Nazanin Bold.TTF"):
        with open("0 Nazanin Bold.TTF", "rb") as f:
            font_bold = base64.b64encode(f.read()).decode()
    
    if font_regular and font_bold:
        font_css = f"""
        <style>
          @font-face {{
            font-family: 'Nazanin';
            src: url(data:font/truetype;charset=utf-8;base64,{font_regular}) format('truetype');
            font-weight: normal;
          }}
          @font-face {{
            font-family: 'Nazanin';
            src: url(data:font/truetype;charset=utf-8;base64,{font_bold}) format('truetype');
            font-weight: bold;
          }}
          * {{
            font-family: 'Nazanin', 'Vazirmatn', Tahoma, sans-serif !important;
          }}
        </style>
        """
        st.markdown(font_css, unsafe_allow_html=True)
# Initialize the app
load_css()
load_font_css()

# Header Section
st.markdown("""
<div class="main-header">
    <div class="main-title">ğŸ“‹ Ø³Ø§Ù…Ø§Ù†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø²ÙˆÙ…Ù‡</div>
    <div class="main-subtitle">Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡</div>
</div>
""", unsafe_allow_html=True)

# Create tabs for different sections
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ", "ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø±Ø²ÙˆÙ…Ù‡", "âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª", "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´Ø§Øª"])

with tab1:
    # Stats Row
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="stats-card">
            <div class="stats-number">0</div>
            <div class="stats-label">Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="stats-card" style="background: linear-gradient(135deg, #FF6B6B 0%, #FF8E53 100%);">
            <div class="stats-number">0</div>
            <div class="stats-label">Ø±Ø²ÙˆÙ…Ù‡ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯Ù‡</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="stats-card" style="background: linear-gradient(135deg, #4ECDC4 0%, #44A08D 100%);">
            <div class="stats-number">0%</div>
            <div class="stats-label">Ù†Ø±Ø® Ù¾Ø°ÛŒØ±Ø´</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div class="stats-card" style="background: linear-gradient(135deg, #FFD93D 0%, #FF6B6B 100%);">
            <div class="stats-number">0</div>
            <div class="stats-label">Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<br>", unsafe_allow_html=True)
    
    # Main Content Area
    col_left, col_right = st.columns([2, 1])
    
    with col_left:
        st.markdown("""
        <div class="custom-card">
            <div class="card-header">
                <span class="card-icon">ğŸ“</span>
                <span class="card-title">Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§</span>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        uploaded_file = st.file_uploader(
            "ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø­Ø§ÙˆÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯",
            type=["xlsx", "xls"],
            help="ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§ÛŒØ¯ Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø¨Ø§Ø´Ø¯"
        )
        
        if uploaded_file:
            st.markdown("""
            <div class="success-box">
                âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯
            </div>
            """, unsafe_allow_html=True)
            
            # Read Excel with proper header handling
            df = pd.read_excel(uploaded_file, skiprows=2)  # Skip first 2 header rows
            
            with st.expander("ğŸ‘€ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"):
                st.dataframe(df.head(10), use_container_width=True)
    
    with col_right:
        st.markdown("""
        <div class="custom-card">
            <div class="card-header">
                <span class="card-icon">ğŸ’¡</span>
                <span class="card-title">Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø³Ø±ÛŒØ¹</span>
            </div>
            <div style="padding: 0.5rem 0;">
                <p>ğŸ“Œ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯</p>
                <p>ğŸ“Œ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯</p>
                <p>ğŸ“Œ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯</p>
                <p>ğŸ“Œ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯</p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="custom-card" style="background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);">
            <div class="card-header">
                <span class="card-icon">ğŸ¯</span>
                <span class="card-title">ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…</span>
            </div>
            <div style="text-align: center; padding: 1rem;">
                <div style="font-size: 2rem;">ğŸŸ¢</div>
                <div style="font-weight: 600;">Ø³ÛŒØ³ØªÙ… ÙØ¹Ø§Ù„</div>
                <div style="color: #666; font-size: 0.9rem;">Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´</div>
            </div>
        </div>
        """, unsafe_allow_html=True)

with tab2:
    st.markdown("""
    <div class="custom-card">
        <div class="card-header">
            <span class="card-icon">ğŸ¯</span>
            <span class="card-title">Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        job_titles = [
            "ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§",
            "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ú©Ø§Ù†ÛŒ",
            "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
            "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø±Ø§Ú©Ø² Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ",
            "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ùˆ Ù‡ÙˆØ´ ØªØ¬Ø§Ø±ÛŒ"
        ]
        
        selected_jobs = st.multiselect(
            "Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±",
            job_titles,
            help="Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯"
        )
    
    with col2:
        custom_job = st.text_input(
            "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ",
            placeholder="Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ Ø¬Ø¯ÛŒØ¯ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯"
        )
    
    st.markdown("""
    <div class="custom-card">
        <div class="card-header">
            <span class="card-icon">ğŸ’¼</span>
            <span class="card-title">Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    skills = [
        "Python", "JavaScript", "SQL", "Machine Learning",
        "Data Analysis", "GIS", "Remote Sensing"
    ]
    
    selected_skills = st.multiselect(
        "Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ",
        skills,
        help="Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯"
    )
    
    col1, col2, col3 = st.columns(3)
    
    with col2:
        if st.button("ğŸš€ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ", use_container_width=True):
            st.balloons()
            st.markdown("""
            <div class="info-box">
                â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§... Ù„Ø·ÙØ§ ØµØ¨Ø± Ú©Ù†ÛŒØ¯
            </div>
            """, unsafe_allow_html=True)

with tab3:
    st.markdown("""
    <div class="custom-card">
        <div class="card-header">
            <span class="card-icon">âš™ï¸</span>
            <span class="card-title">ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.slider("Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù…ØªÛŒØ§Ø² Ù‚Ø¨ÙˆÙ„ÛŒ", 0, 100, 70, help="Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø² Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯")
        st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø±Ø²ÙˆÙ…Ù‡ Ø¯Ø± Ù‡Ø± Ø¯Ø³ØªÙ‡", 5, 50, 10)
        st.selectbox("Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", ["Gemini 2.5 Flash", "Gemini Pro", "GPT-4"])
    
    with col2:
        st.number_input("Ø­Ø¯Ø§Ù‚Ù„ Ø³Ù†", 18, 65, 22)
        st.number_input("Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ù†", 18, 65, 35)
        st.number_input("Ø­Ù‚ÙˆÙ‚ Ù¾Ø§ÛŒÙ‡ (Ù…ÛŒÙ„ÛŒÙˆÙ† ØªÙˆÙ…Ø§Ù†)", 10, 100, 20)

with tab4:
    st.markdown("""
    <div class="custom-card">
        <div class="card-header">
            <span class="card-icon">ğŸ“ˆ</span>
            <span class="card-title">Ú¯Ø²Ø§Ø±Ø´ ØªØ­Ù„ÛŒÙ„ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sample data for demonstration
    if st.checkbox("Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ Ú¯Ø²Ø§Ø±Ø´"):
        sample_data = pd.DataFrame({
            'Ù†Ø§Ù…': ['Ø¹Ù„ÛŒ', 'Ù…Ø±ÛŒÙ…', 'Ø­Ø³Ù†', 'Ø²Ù‡Ø±Ø§'],
            'Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ': [85, 92, 78, 88],
            'ÙˆØ¶Ø¹ÛŒØª': ['ØªØ£ÛŒÛŒØ¯', 'ØªØ£ÛŒÛŒØ¯', 'Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø±', 'ØªØ£ÛŒÛŒØ¯'],
            'Ù…ÙˆÙ‚Ø¹ÛŒØª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ': ['ØªÙˆØ³Ø¹Ù‡â€ŒØ¯Ù‡Ù†Ø¯Ù‡', 'ØªØ­Ù„ÛŒÙ„Ú¯Ø±', 'Ù¾Ø´ØªÛŒØ¨Ø§Ù†', 'Ø·Ø±Ø§Ø­']
        })
        
        st.dataframe(sample_data, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ Excel",
                data=b"",  # This would be your actual Excel data
                file_name="report.xlsx",
                mime="application/vnd.ms-excel",
                use_container_width=True
            )
        with col2:
            st.download_button(
                "ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú¯Ø²Ø§Ø±Ø´ PDF",
                data=b"",  # This would be your actual PDF data
                file_name="report.pdf",
                mime="application/pdf",
                use_container_width=True
            )
def style_excel(path): 
    wb = openpyxl.load_workbook(path) 
    ws = wb.active 

    header_fill = PatternFill(start_color="B7DEE8", end_color="B7DEE8", fill_type="solid")
    row_fill_odd = PatternFill(start_color="FFFFFF", end_color="FFFFFF", fill_type="solid")
    row_fill_even = PatternFill(start_color="EAF3FA", end_color="EAF3FA", fill_type="solid")

    header_font = Font(bold=True, name='B Homa', size=14)
    row_font = Font(name='B Homa', size=12)
    center_align = Alignment(horizontal="center", vertical="center", wrap_text=True)

    border = Border(
        left=Side(border_style="thin", color="CCCCCC"),
        right=Side(border_style="thin", color="CCCCCC"),
        top=Side(border_style="thin", color="CCCCCC"),
        bottom=Side(border_style="thin", color="CCCCCC"),
    )

    for cell in ws[1]:
        cell.fill = header_fill
        cell.font = header_font
        cell.alignment = center_align
        cell.border = border

    for idx, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column), start=2):
        fill = row_fill_even if idx % 2 == 0 else row_fill_odd
        for cell in row:
            cell.fill = fill
            cell.font = row_font
            cell.alignment = center_align
            cell.border = border

    for col in ws.columns:
        if col[0].value == "ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ":
            for cell in col:
                cell.alignment = Alignment(wrap_text=True, vertical="top", horizontal="center")

    for col in ws.columns: 
        max_length = 0 
        column = col[0].column_letter 
        for cell in col: 
            try: 
                if cell.value:
                    max_length = max(max_length, len(str(cell.value))) 
            except: 
                pass 
        adjusted_width = min(max_length + 3, 50) 
        ws.column_dimensions[column].width = adjusted_width 

    ws.freeze_panes = ws["A2"] 

    wb.save(path)


class RotatingGeminiLLM:
    def __init__(self, api_keys, model="gemini-2.5-flash"):
        self.api_keys = api_keys
        self.model = model
        self.idx = 0

    def invoke(self, messages):
        num_keys = len(self.api_keys)
        start_idx = self.idx
        for i in range(num_keys):
            api_key = self.api_keys[self.idx]
            llm = ChatGoogleGenerativeAI(model=self.model, google_api_key=api_key)
            try:
                result = llm.invoke(messages)
                return result
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¨Ø§ API {api_key[:10]}...: {str(e)}")
                self.idx = (self.idx + 1) % num_keys
                if self.idx == start_idx:
                    raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")
        raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")

rotating_llm = RotatingGeminiLLM(API_KEYS)

def safe_generate_content(*, model, contents, config):
    for api_key in API_KEYS:
        try:
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model=model,
                contents=contents,
                config=config
            )
            return response
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¨Ø§ API {api_key[:10]}...: {str(e)}")
            continue
    raise RuntimeError("âŒ ØªÙ…Ø§Ù… API KeyÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯.")

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key="AIzaSyC8tN4kY2QU5ACRacPazzRQeJPtAC08Vm8")

RESULT_FILE_PATH = Path("resume_results.xlsx")
if RESULT_FILE_PATH.exists():
    RESULT_FILE_PATH.unlink()

os.environ['SSL_CERT_FILE'] = certifi.where()

proxy_url = "http://172.16.217.234:33525"
os.environ['HTTP_PROXY'] = proxy_url
os.environ['HTTPS_PROXY'] = proxy_url

test_url = "https://generativelanguage.googleapis.com/v1beta/models"
try:
    response = requests.get(test_url, proxies={"http": proxy_url, "https": proxy_url}, timeout=5)
    if response.status_code == 200:
        print("âœ… Ø§ØªØµØ§Ù„ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø§Ø³Øª.")
    else:
        print(f"âš ï¸ Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {response.status_code}")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ù¾Ø±Ø§Ú©Ø³ÛŒ: {e}")

pd.set_option('display.max_rows', None)
OUTPUT_ALL_PATH = Path("recruitment_score.xlsx")
BATCH_SIZE = 10
RESULT_FILE_PATH = Path("resume_results.xlsx")

if 'live_results' not in st.session_state:
    st.session_state['live_results'] = []

JOB_PROFILES = [
    {
        "id": "job_rnd_01",
        "title": "ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ùˆ Ø§Ø­ØµØ§ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø°ÛŒÙ†ÙØ¹Ø§Ù† Ø¯Ø± Ø­ÙˆØ²Ù‡ Ø²ÛŒØ±Ø³Ø§Ø®Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø­Ø¬ÛŒÙ…ØŒ Ù„Ø§Ú¯ Ùˆ Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø±",
            "ØªÙˆØ³Ø¹Ù‡ Ùˆ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø´Ø§Ù…Ù„ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒØŒ Ú¯Ø±Ø¯Ø´ Ú©Ø§Ø± Ùˆ Ù¾Ø±ØªØ§Ù„",
            "Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø²ÛŒØ±Ø³Ø§Ø®Øª Ùˆ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§",
            "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ùˆ Ù†Ú¯Ù‡Ø¯Ø§Ø´Øª Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ùˆ Ù¾Ø§Ø³Ø® Ø¨Ù‡ ØªÛŒÚ©Øªâ€ŒÙ‡Ø§",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ø´ Ø³Ø§Ù…Ø§Ù†Ù‡â€ŒÙ‡Ø§"
        ],
        "competencies_technical": [
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ùˆ Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"},
            {"name": "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±"},
            {"name": "Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Ø¨Ú©â€ŒØ§Ù†Ø¯ ÛŒØ§ ÙØ±Ø§Ù†Øª (Ù…Ø«Ù„ Python ÛŒØ§ JavaScript)"},
            {"name": "Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"}
        ],
        "majors": ["Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ ÙÙ†ÛŒ Ùˆ Ù…Ù‡Ù†Ø¯Ø³ÛŒ"]
    },
    {
        "id": "job_spatial_01",
        "title": "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ú©Ø§Ù†ÛŒ",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ù…Ú©Ø§Ù†ÛŒ",
            "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ GIS Ùˆ RS",
            "ÙØ±Ø§ÛŒÙ†Ø¯ ETL Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒ",
            "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± GIS/RS",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ Ùˆ Ù…Ø§Ù…ÙˆØ±ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù†ÛŒ"
        ],
        "competencies_technical": [
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ø³Ù†Ø¬Ø´ Ø§Ø² Ø¯ÙˆØ±"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ RS Ù…Ø§Ù†Ù†Ø¯ ENVIØŒ ERDASØŒ SNAP"},
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ / Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±"},
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Python / MATLAB"},
            {"name": "Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±Ù‡Ø§ÛŒ GIS Ù…Ø§Ù†Ù†Ø¯ ArcGIS/QGIS"}
        ],
        "majors": ["Ù†Ù‚Ø´Ù‡â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ø¨Ø±Ù‚"]
    },
    {
        "id": "job_ai_01",
        "title": "ØªÙˆØ³Ø¹Ù‡ Ø±Ø§Ù‡Ú©Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
        "tasks": [
            "ØªØ­Ù„ÛŒÙ„ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ± Ø¨Ø§ ØªØ§Ú©ÛŒØ¯ Ø¨Ø± AI",
            "Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†",
            "Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ MLOps",
            "ØªÙ‡ÛŒÙ‡ Ú¯Ø²Ø§Ø±Ø´Ø§Øª ØªØ­Ù„ÛŒÙ„ÛŒ",
            "Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ø´ Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ AI"
        ],
        "competencies_technical": [
            {"name": "Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¢Ù…Ø§Ø±ÛŒ / ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†"},
            {"name": "Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ Python / R / GAMS"},
            {"name": "Ú©Ø§Ø± Ø¨Ø§ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡"}
        ],
        "majors": ["Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±", "Ø±ÛŒØ§Ø¶ÛŒ", "Ø¢Ù…Ø§Ø±", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø§Ù‚ØªØµØ§Ø¯", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ù…Ø§Ù„ÛŒ", "Ø¨Ø±Ù‚"]
    },
    {
        "id": "job_research_01",
        "title": "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø±Ø§Ú©Ø² Ù¾Ú˜ÙˆÙ‡Ø´ÛŒ",
        "tasks": [
            "Ø§Ø­ØµØ§ Ù…Ø³Ø§Ø¦Ù„ ÙÙ†Ø§ÙˆØ±Ø§Ù†Ù‡ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ…Ø­ÙˆØ±",
            "Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø³Ø§Ù…Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ Ù†Ø¸Ø§Ù… Ù…Ø³Ø§Ø¦Ù„",
            "Ù…Ø·Ø§Ù„Ø¹Ø§Øª ØªØ·Ø¨ÛŒÙ‚ÛŒ Ø¯Ø± Ø­ÙˆØ²Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§Ù‡Ø¨Ø±Ø¯ÛŒ AI",
            "Ø±ØµØ¯ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙÙ†Ø§ÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†ÙˆØ¸Ù‡ÙˆØ±"
        ],
        "competencies_technical": [
            {"name": "Microsoft Office"},
            {"name": "Ù…Ø¨Ø§Ù†ÛŒ Ø¹Ù„Ù… Ø¯Ø§Ø¯Ù‡ Ùˆ IT"},
            {"name": "Ø§ØµÙˆÙ„ ØªØ­Ù‚ÛŒÙ‚ Ùˆ ØªÙˆØ³Ø¹Ù‡"}
        ],
        "majors": ["Ù…Ø¯ÛŒØ±ÛŒØª", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÛŒ", "Ø¹Ù„ÙˆÙ… Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"]
    },
    {
        "id": "job_analysis_01",
        "title": "Ú©Ø§Ø±Ø´Ù†Ø§Ø³ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ùˆ Ù‡ÙˆØ´ ØªØ¬Ø§Ø±ÛŒ",
        "tasks": [
            "Ú¯Ø±ÙˆÙ‡ Ø¨Ù†Ø¯ÛŒ Ùˆ Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª",
            "ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø±",
            "ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ ETL",
            "Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ø§Ø³Ù†Ø§Ø¯ Ø±Ø§Ù‡Ø¨Ø±Ø¯ÛŒ ",
            "Ù†Ø§Ù…Ù‡ Ù†Ú¯Ø§Ø±ÛŒ Ùˆ Ù…Ú©Ø§ØªØ¨Ø§Øª Ø§Ø¯Ø§Ø±ÛŒ",
            "Ø¨ØµØ±ÛŒ Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ù‡Ø§"
        ],
        "competencies_technical": [
            {"name": "Microsoft Office"},
            {"name": "Ø´Ù†Ø§Ø®Øª Ùˆ ØªØ­Ù„ÛŒÙ„ Ú©Ø³Ø¨ Ùˆ Ú©Ø§Ø±"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù…ØµÙˆØ±Ø³Ø§Ø²ÛŒ Ù…Ø§Ù†Ù†Ø¯ powerBI"},
            {"name": "Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ù…Ø§Ù†Ù†Ø¯ KNIME"},
            {"name": "Ø¢Ø´Ù†Ø§ÛŒÛŒ Ø¨Ø§ Ø²Ø§Ù† Ù‡Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†ÙˆÛŒØ³ÛŒ Ù…Ø§Ù†Ù†Ø¯ python , R"}
        ],
        "majors": ["Ù…Ø¯ÛŒØ±ÛŒØª", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ ØµÙ†Ø§ÛŒØ¹", "Ø¹Ù„ÙˆÙ… Ø§Ù‚ØªØµØ§Ø¯ÛŒ", "Ù…Ù‡Ù†Ø¯Ø³ÛŒ Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±"]
    }
]

universities_info = [
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù† (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø´Ø±ÛŒÙ (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ± (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª Ø§ÛŒØ±Ø§Ù† (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø¬Ù‡ Ù†ØµÛŒØ± (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø®ÙˆØ§Ø±Ø²Ù…ÛŒ (Ø¨Ø±ØªØ±ØŒ Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ÙØ±Ø¯ÙˆØ³ÛŒ Ù…Ø´Ù‡Ø¯ (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªØ¨Ø±ÛŒØ² (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø§ØµÙÙ‡Ø§Ù† (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§ØµÙÙ‡Ø§Ù† (Ø¯ÙˆÙ„ØªÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¢Ø²Ø§Ø¯ Ø§Ø³Ù„Ø§Ù…ÛŒ (Ø¢Ø²Ø§Ø¯)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ù¾ÛŒØ§Ù… Ù†ÙˆØ± (Ù¾ÛŒØ§Ù… Ù†ÙˆØ±)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ (ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ)",
    "Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ (Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ)"
]

AGENT_WEIGHTS = {
    "SkillAgent": 0.40,
    "ExperienceAgent": 0.30,
    "EducationAgent": 0.20,
    "VolunteeringAgent": 0.05,
    "SoftSkillsAgent": 0.05
}

def score_text_section(text): 
    if not text or str(text).strip() == "": 
        return 30

    prompt = f"""  
    Please rate the quality of the following resume section on a scale of 0 to 100.  
    Consider clarity, relevance, and value in a resume.  
    Return only a number between 0.0 and 1.0.  

    Text: 
    \"\"\" 
    {text} 
    \"\"\" 
    """ 

    try: 
        response = llm.invoke([HumanMessage(content=prompt)]) 
        score = float(response.content.strip()) 
        return round(max(0.0, min(1.0, score)) * 100, 2)
    except: 
        return 30

def process_batch(batch_df, prompt_text):
    payload = {
        "employer requirements": prompt_text,
        "applicant information": [
            {"resume": " ".join([str(row[col]) for col in batch_df.columns]), "id": str(idx)}
            for idx, row in batch_df.iterrows()
        ]
    }
    try:
        response = safe_generate_content(
            model='gemini-2.5-flash',
            contents=json.dumps(payload, ensure_ascii=False),
            config={
                'response_mime_type': 'application/json',
                'system_instruction': """
Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:
- ØªØ·Ø§Ø¨Ù‚ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ
- ØªØ·Ø§Ø¨Ù‚ Ø³ÙˆØ§Ø¨Ù‚ Ø´ØºÙ„ÛŒ
- Ù…Ù‚Ø·Ø¹ Ùˆ Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ Ù…Ø±ØªØ¨Ø·
- Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¯ÙˆÙ„ØªÛŒ Ùˆ Ù…Ø¹ØªØ¨Ø±
- Ø³Ù† Ù…Ù†Ø§Ø³Ø¨ (Û²Û² ØªØ§ Û³Ûµ)
- Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ (Û²Û° ØªØ§ Û´Ûµ Ù…ÛŒÙ„ÛŒÙˆÙ†)
Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† Û± ØªØ§ Û±Û° Ø¨Ø¯Ù‡ÛŒØ¯. Ø§Ú¯Ø± Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯: 'Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª'.
""",
                'response_schema': {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "score": {"type": "number", "nullable": False},
                            "check_id": {"type": "string", "nullable": False},
                            "why": {"type": "string", "nullable": False}
                        }
                    }
                },
                'temperature': 0
            }
        )
        result = json.loads(response.candidates[0].content.parts[0].text)
        return pd.DataFrame(result)
    except Exception:
        return pd.DataFrame([{
            "score": 1.0,
            "check_id": str(idx),
            "why": "Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª"
        } for idx, row in batch_df.iterrows()])

def to_excel(df, path):
    df.to_excel(path, index=False)

def match_resume_to_job_parallel(resume_text, job_profiles, threshold=7):
    best_match = None
    best_score = -1
    best_reason = ""
    log_messages = []

    def evaluate_job_with_key(api_key, job):
        prompt = f"""Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²ÛŒØ±:
Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ:
Ø¹Ù†ÙˆØ§Ù†: {job['title']}
Ø´Ø±Ø­ ÙˆØ¸Ø§ÛŒÙ: {'Ø› '.join(job['tasks'])}
Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ: {'Ø› '.join([c['name'] for c in job.get('competencies_technical', [])])}
Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·: {'Ø› '.join(job.get('majors', []))}

Ø¢ÛŒØ§ Ø§ÛŒÙ† Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ø§ÛŒÙ† Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ ØªØ·Ø§Ø¨Ù‚ Ø¯Ø§Ø±Ø¯ØŸ Ù„Ø·ÙØ§Ù‹:
- ÛŒÚ© Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒÙ† Û° ØªØ§ 100 Ø¨Ø¯Ù‡
- Ø¯Ø± ØµÙˆØ±Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù†ØŒ Ø¯Ù„ÛŒÙ„ Ø±Ø§ Ø´Ø±Ø­ Ø¨Ø¯Ù‡
- Ø¯Ø± ØµÙˆØ±Øª Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù†ØŒ Ø¨Ù†ÙˆÛŒØ³ Ú†Ø±Ø§ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª

Ù„Ø·ÙØ§Ù‹ Ù‡Ù…ÛŒØ´Ù‡ Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Ø²ÛŒØ± Ùˆ Ø¨Ø§ Ù‡Ø±Ø¯Ùˆ Ø¨Ø®Ø´ Ø¨Ø¯Ù‡:
Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯ Ø§Ø² 0 ØªØ§ 100]
Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ ÙˆØ§Ø¶Ø­ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø´Ø§Ù…Ù„ Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ ÛŒØ§ Ø¹Ø¯Ù… Ø§Ù†ØªØ®Ø§Ø¨]

"""
        try:
            response = safe_generate_content_for_key(
                api_key=api_key,
                model="gemini-2.5-flash",
                contents=prompt,
                config={"temperature": 0}
            )
            if isinstance(response, dict) and "error" in response:
                return None

            text = response.candidates[0].content.parts[0].text.strip()
            lines = [line.strip() for line in text.splitlines() if line.strip() != ""]

            score = -1
            reason = "ØªÙˆØ¶ÛŒØ­ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"

            for line in lines:
                if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
                    try:
                        score = int("".join(filter(str.isdigit, line)))
                    except:
                        score = -1
                if line.startswith("Ø¯Ù„ÛŒÙ„"):
                    reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()

            if reason == "ØªÙˆØ¶ÛŒØ­ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª":
                for i, line in enumerate(lines):
                    if "Ø§Ù…ØªÛŒØ§Ø²" in line and i + 1 < len(lines):
                        possible_reason = lines[i + 1]
                        if not possible_reason.startswith("Ø§Ù…ØªÛŒØ§Ø²") and "Ø¯Ù„ÛŒÙ„" not in possible_reason:
                            reason = possible_reason
                            break

            return {"title": job["title"], "score": score, "reason": reason}

        except Exception as e:
            return None

    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_job = {
            executor.submit(evaluate_job_with_key, api_key, job): job
            for api_key, job in zip(API_KEYS * (len(job_profiles) // len(API_KEYS) + 1), job_profiles)
        }

        for future in concurrent.futures.as_completed(future_to_job):
            result = future.result()
            if result:
                log_messages.append(f"ğŸ”¹ {result['title']} â†’ Ø§Ù…ØªÛŒØ§Ø²: {result['score']} | Ø¯Ù„ÛŒÙ„: {result['reason']}")
                if result["score"] > best_score:
                    best_score = result["score"]
                    best_match = result["title"]
                    best_reason = result["reason"]

    log = "\n".join(log_messages)

    if best_score >= threshold:
        return best_match, best_reason, log
    else:
        return "Ù…Ù†Ø§Ø³Ø¨ Ù‡ÛŒÚ†Ú©Ø¯Ø§Ù… Ø§Ø² Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯", best_reason or "Ø±Ø²ÙˆÙ…Ù‡ ØªØ·Ø§Ø¨Ù‚ Ú©Ø§ÙÛŒ Ø¨Ø§ Ù‡ÛŒÚ†â€ŒÚ©Ø¯Ø§Ù… Ø§Ø² Ø´ØºÙ„â€ŒÙ‡Ø§ Ù†Ø¯Ø§Ø±Ø¯.", log


def apply_matching_to_batch(batch_df):
    all_results = []

    for idx, row in batch_df.iterrows():
        resume_text = " ".join([str(row[col]) for col in batch_df.columns])
        match_df = evaluate_resume_against_all_jobs(resume_text, JOB_PROFILES)

        match_df["Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡"] = idx + 1
        match_df["Ù†Ø§Ù…"] = row.get("Ù†Ø§Ù…", "")
        match_df["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"] = row.get("Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ", "")

        all_results.append(match_df)

    final_df = pd.concat(all_results, ignore_index=True)
    return final_df

top_universities = ['Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø´Ø±ÛŒÙ', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØªÙ‡Ø±Ø§Ù†', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ ØµÙ†Ø¹ØªÛŒ Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ±', 'Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª Ø§ÛŒØ±Ø§Ù†']
public_keywords = ['ØµÙ†Ø¹ØªÛŒ', 'ØªÙ‡Ø±Ø§Ù†', 'Ø§Ù…ÛŒØ±Ú©Ø¨ÛŒØ±', 'Ø¹Ù„Ù… Ùˆ ØµÙ†Ø¹Øª', 'ÙØ±Ø¯ÙˆØ³ÛŒ', 'ØªØ¨Ø±ÛŒØ²', 'Ø§ØµÙÙ‡Ø§Ù†', 'Ø¯ÙˆÙ„ØªÛŒ']

def is_public_university(univ_name):
    return any(keyword in str(univ_name) for keyword in public_keywords)

def is_top_university(univ_name):
    return any(top in str(univ_name) for top in top_universities)

def color_score_column(val):
    if val >= 9:
        color = '#00C853'
    elif val >= 8:
        color = '#AEEA00'
    elif val >= 7:
        color = '#FFD600'
    elif val >= 6:
        color = '#FF9100'
    elif val >= 5:
        color = '#FF3D00'
    else:
        color = '#D50000'
    return f'background-color: {color}; color: white; font-weight: bold'


def adjust_score(row):
    score = row['score']
    if 'Ø³Ù†' in row and (row['Ø³Ù†'] < 22 or row['Ø³Ù†'] > 35):
        score -= 1
    if 'Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ' in row and (row['Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ'] < 20 or row['Ø­Ù‚ÙˆÙ‚ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ'] > 45):
        score -= 1
    if 'Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ' in row and 'Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ' not in str(row['Ù…Ù‚Ø·Ø¹ ØªØ­ØµÛŒÙ„ÛŒ']):
        score -= 0.5
    univ = row.get('Ù†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡', '')
    if is_public_university(univ):
        score += 0.5
    if is_top_university(univ):
        score += 0.5
    return max(min(score, 10), 1.0)

def skill_agent(resume, skills):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø±Ø§ Ø¯Ø± Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: {', '.join(skills)}
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}
    
    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

skill_tool = Tool(
    name="SkillAgent",
    func=lambda input: skill_agent(input["resume"], input["skills"]),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ÛŒ"
)
experience_tool = Tool(
    name="ExperienceAgent",
    func=lambda input: experience_agent(input["resume"], input["required_experience_desc"]),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ¬Ø±Ø¨Ù‡ Ø´ØºÙ„ÛŒ"
)
education_tool = Tool(
    name="EducationAgent",
    func=lambda input: education_agent(
        input["resume"],
        input["university_list"],
        input["major_list"],
        input["job_profile_title"]
    ),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ØªØ­ØµÛŒÙ„Ø§Øª Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ÛŒ"
)
volunteering_tool = Tool(
    name="VolunteeringAgent",
    func=lambda input: volunteering_agent(input["resume"], input.get("volunteering_field")),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡"
)
softskills_tool = Tool(
    name="SoftSkillsAgent",
    func=lambda input: softskills_agent(input["resume"], input.get("about_me_field")),
    description="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ùˆ Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ ÙØ±Ø¯ÛŒ"
)

def experience_agent(resume, required_experience_desc):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· ØªØ¬Ø±Ø¨Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø§Ø² Ù†Ø¸Ø± Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø²ÛŒØ± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ø³Ø§Ø¨Ù‚Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±: {required_experience_desc}
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}
    
    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ø³Ø§Ø¨Ù‚Ù‡ Ú©Ø§Ø±ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø¨Ø§ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason


def education_agent(resume, universities_info, major_list, job_profile_title):
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø®Ø´ ØªØ­ØµÛŒÙ„Ø§Øª Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ ÙÙ‚Ø· Ø§Ø² Ù†Ø¸Ø± Ø³Ù‡ Ù…Ø¹ÛŒØ§Ø± Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Û±. Ø§Ø¹ØªØ¨Ø§Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ùˆ Ù†ÙˆØ¹ Ø¢Ù† (Ø¯Ø± ÙÙ‡Ø±Ø³Øª Ø²ÛŒØ± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ùˆ Ù†ÙˆØ¹ Ù‡Ø±Ú©Ø¯Ø§Ù… Ø¢Ù…Ø¯Ù‡ Ø§Ø³ØªØŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±ØªØ± Ùˆ Ø¯ÙˆÙ„ØªÛŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¢Ø²Ø§Ø¯ Ùˆ Ù¾ÛŒØ§Ù… Ù†ÙˆØ± Ø§Ù…ØªÛŒØ§Ø² Ù…ØªÙˆØ³Ø·ØŒ ØºÛŒØ±Ø§Ù†ØªÙØ§Ø¹ÛŒ Ùˆ Ø¹Ù„Ù…ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ±):
    {chr(10).join(universities_info)}
    Û². ØªØ·Ø§Ø¨Ù‚ Ø±Ø´ØªÙ‡ ØªØ­ØµÛŒÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ "{job_profile_title}" (Ù„ÛŒØ³Øª Ø±Ø´ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø·Ù„ÙˆØ¨: {', '.join(major_list)})
    Û³. Ù…Ø¯Øª Ø²Ù…Ø§Ù† ØªØ­ØµÛŒÙ„ Ú©Ø§Ø±Ø´Ù†Ø§Ø³ÛŒ (Ø²ÛŒØ± Û´ Ø³Ø§Ù„ Ø¹Ø§Ù„ÛŒØŒ Û´ Ø³Ø§Ù„ Ø®ÙˆØ¨ØŒ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û´ Ø³Ø§Ù„ Ø¶Ø¹ÛŒÙ)
    
    Ø±Ø²ÙˆÙ…Ù‡:
    {resume}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…ÛŒØ²Ø§Ù† Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ ØªØ­ØµÛŒÙ„Ø§Øª Ø±Ø²ÙˆÙ…Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù†ÛŒØ§Ø²Ù‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def volunteering_agent(resume, volunteering_field=None):
    field = volunteering_field if volunteering_field else resume
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· ÙØ¹Ø§Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ùˆ Ú©Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    Ø§Ú¯Ø± ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ù…Ø±ØªØ¨Ø· Ùˆ ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø± (Ø¯Ø± Ø³Ø·Ø­ Ø¨Ø§Ù„Ø§) Ø¨Ø§Ø´Ø¯ØŒ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ø¯Ù‡ØŒ Ø§Ú¯Ø± Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ Ú©Ù… Ø¨Ø§Ø´Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†.
    Ø±Ø²ÙˆÙ…Ù‡/ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡:
    {field}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡ Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def softskills_agent(resume, about_me_field=None):
    field = about_me_field if about_me_field else resume
    prompt = f"""
    Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙÙ‚Ø· Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ùˆ Ø´Ø§ÛŒØ³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ±Ø¯ÛŒ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†:
    ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„: Ú©Ø§Ø± ØªÛŒÙ…ÛŒØŒ Ø§Ø±ØªØ¨Ø§Ø· Ù…ÙˆØ«Ø±ØŒ Ù…Ø¯ÛŒØ±ÛŒØªØŒ Ù…Ø³Ø¦ÙˆÙ„ÛŒØªâ€ŒÙ¾Ø°ÛŒØ±ÛŒØŒ Ø¯Ù‚ØªØŒ Ù…ÛŒÙ„ Ø¨Ù‡ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ù‡ÙˆØ´ Ù‡ÛŒØ¬Ø§Ù†ÛŒ (EQ) Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†.
    Ø§Ú¯Ø± Ø±Ø²ÙˆÙ…Ù‡ ÛŒØ§ Ø¨Ø®Ø´ 'Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†' Ø´ÙˆØ§Ù‡Ø¯ Ù‚ÙˆÛŒ Ø§Ø² Ø§ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø§Ø±Ø¯ Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø§Ù„Ø§ Ø¨Ø¯Ù‡ØŒ Ø§Ú¯Ø± Ù†Ø¯Ø§Ø´Øª ÛŒØ§ Ø¶Ø¹ÛŒÙ Ø¨ÙˆØ¯ Ø§Ù…ØªÛŒØ§Ø² Ù¾Ø§ÛŒÛŒÙ†.
    Ù…ØªÙ† Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„:
    {field}

    ÛŒÚ© Ø¹Ø¯Ø¯ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ù‡ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø±Ù… Ø¨Ø¯Ù‡ Ùˆ ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¯Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù†ÙˆÛŒØ³.
    ÙØ±Ù…Øª Ø¯Ù‚ÛŒÙ‚ Ù¾Ø§Ø³Ø®:
    Ø§Ù…ØªÛŒØ§Ø²: [ÛŒÚ© Ø¹Ø¯Ø¯]
    Ø¯Ù„ÛŒÙ„: [ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ú©ÙˆØªØ§Ù‡]
    """
    messages = [HumanMessage(content=prompt)]
    result = rotating_llm.invoke(messages)
    text = result.content
    lines = [l.strip() for l in text.splitlines() if l.strip()]  
    score, reason = 0, ""
    for line in lines:
        if line.startswith("Ø§Ù…ØªÛŒØ§Ø²"):
            score = int("".join(filter(str.isdigit, line)))
        if line.startswith("Ø¯Ù„ÛŒÙ„"):
            reason = line.replace("Ø¯Ù„ÛŒÙ„:", "").strip()
    return score, reason

def scoring_chain(
    resume,
    skills,
    required_experience_desc,
    universities_info,
    major_list,
    job_profile_title,
    volunteering_field=None,
    about_me_field=None
):
    results = {}

    skill_score, skill_reason = skill_agent(resume, skills)
    results["SkillAgent"] = {"score": skill_score, "reason": skill_reason}

    exp_score, exp_reason = experience_agent(resume, required_experience_desc)
    results["ExperienceAgent"] = {"score": exp_score, "reason": exp_reason}

    edu_score, edu_reason = education_agent(resume, universities_info, major_list, job_profile_title)
    results["EducationAgent"] = {"score": edu_score, "reason": edu_reason}

    vol_score, vol_reason = volunteering_agent(resume, volunteering_field)
    results["VolunteeringAgent"] = {"score": vol_score, "reason": vol_reason}

    soft_score, soft_reason = softskills_agent(resume, about_me_field)
    results["SoftSkillsAgent"] = {"score": soft_score, "reason": soft_reason}

    results["VolunteeringAgent"]["score"] = score_text_section(vol_reason)
    results["SoftSkillsAgent"]["score"] = score_text_section(soft_reason)

    final_score = 0
    for agent, w in AGENT_WEIGHTS.items():
        final_score += results[agent]["score"] * w

    final_score = round(final_score / sum(AGENT_WEIGHTS.values()), 2)
    results["FinalScore"] = final_score

    return results


def evaluate_resume_against_all_jobs(resume_text, job_profiles):
    prompt = f"""Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÛŒÚ© Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒØ´Ø¯Ù‡ØŒ ÛŒÚ© Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ ÛŒÚ© Ø¯Ù„ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ø°Ú©Ø± Ú©Ù†ÛŒØ¯.

Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
[
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø§ÙˆÙ„",
    "match_percent": 85,
    "reason": "ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚ ÛŒØ§ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚"
  }},
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø¯ÙˆÙ…",
    "match_percent": 45,
    "reason": "..."
  }}
  ...
]
Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ:
{json.dumps(job_profiles, ensure_ascii=False)}
"""

    try:
        response = safe_generate_content(
            model="gemini-2.5-flash",
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "temperature": 0
            }
        )
        json_text = response.candidates[0].content.parts[0].text.strip()
        parsed = json.loads(json_text)
        return pd.DataFrame(parsed)
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚: {e}")
        return pd.DataFrame()

def process_resume_row(row, row_index):
    resume_text = " ".join([str(row[col]) for col in row.index])
    title, reason, log = match_resume_to_job(resume_text, JOB_PROFILES)

    gemini_df = process_batch(pd.DataFrame([row]), prompt_text="Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ø±Ø²ÙˆÙ…Ù‡")
    initial_score = gemini_df.iloc[0]['score']

    score = adjust_score({**row.to_dict(), 'score': initial_score})

    new_data = row.to_dict()
    new_data.update({
        "Ø±Ø¯ÛŒÙ": row_index + 1,
        "score": score,
        "Ø¯Ù„ÛŒÙ„": gemini_df.iloc[0]['why'],
        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": title,
        "Ø¯Ù„ÛŒÙ„ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ": reason,
        "Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø±Ø³ÛŒ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§": log
    })

    if RESULT_FILE_PATH.exists():
        existing = pd.read_excel(RESULT_FILE_PATH)
        updated = pd.concat([existing, pd.DataFrame([new_data])], ignore_index=True)
    else:
        updated = pd.DataFrame([new_data])

    updated.to_excel(RESULT_FILE_PATH, index=False)

    st.session_state['live_results'].append(new_data)
    return new_data

st.markdown("""
    <style>
    .custom-title {
        font-size: 50px !important;
        color: #1a73e8 !important;
        font-weight: bold !important;
        text-align: center !important;
        margin-top: 40px !important;
        margin-bottom: 30px !important;
    }
    </style>
""", unsafe_allow_html=True)
st.markdown('<div class="custom-title">ğŸ“‹ Ø³Ø§Ù…Ø§Ù†Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±Ø²ÙˆÙ…Ù‡</div>', unsafe_allow_html=True)
st.markdown("<p style='font-size: 16px; color: #555;'>Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒØŒ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ùˆ Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ.</p>", unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“„ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯:", type=["xlsx"])

# Sidebar Enhancement
with st.sidebar:
    st.markdown("""
    <div class="sidebar-card">
        <h3 style="text-align: center;">ğŸ“Š Ø¢Ù…Ø§Ø± Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ</h3>
        <hr style="opacity: 0.3;">
    </div>
    """, unsafe_allow_html=True)
    
    st.metric("Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡", "0", "0")
    st.metric("Ø²Ù…Ø§Ù† Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡", "0:00", "")
    
    st.markdown("""
    <div class="sidebar-card">
        <h3 style="text-align: center;">ğŸ”„ Ø¹Ù…Ù„ÛŒØ§Øª Ø³Ø±ÛŒØ¹</h3>
    </div>
    """, unsafe_allow_html=True)
    
    if st.button("ğŸ”„ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø³ÛŒØ³ØªÙ…", use_container_width=True):
        st.rerun()
    
    if st.button("ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ", use_container_width=True):
        st.success("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯!")
    
    st.markdown("""
    <div class="sidebar-card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
        <div style="text-align: center;">
            <div style="font-size: 2rem;">ğŸ’</div>
            <div style="font-weight: 600;">Ù†Ø³Ø®Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ</div>
            <div style="font-size: 0.9rem; opacity: 0.9;">v2.0.0</div>
        </div>
    </div>
    """, unsafe_allow_html=True)

job_titles = [job['title'] for job in JOB_PROFILES]

selected_job_titles = st.multiselect(
    "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ (Ø§Ù…Ú©Ø§Ù† Ø§Ù†ØªØ®Ø§Ø¨ Ú†Ù†Ø¯ØªØ§ÛŒÛŒ):",
    options=job_titles,
    default=None
)

custom_job_title = st.text_input("Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø´Ù…Ø§ Ø¯Ø± Ù„ÛŒØ³Øª Ù†Ø¨ÙˆØ¯ØŒ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

all_selected_titles = selected_job_titles.copy()
if custom_job_title.strip() != "":
    all_selected_titles.append(custom_job_title.strip())

selected_skills = []
for job in JOB_PROFILES:
    if job["title"] in all_selected_titles:
        selected_skills.extend([c['name'] for c in job.get('competencies_technical', [])])

selected_skills = list(sorted(set(selected_skills)))

edited_skills = st.multiselect(
    "Ù…Ù‡Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯:",
    options=selected_skills,
    default=selected_skills
)

custom_skill = st.text_input("Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ù…Ù‡Ø§Ø±Øª Ø¬Ø¯ÛŒØ¯ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")

all_skills = edited_skills.copy()
if custom_skill.strip() and custom_skill.strip() not in all_skills:
    all_skills.append(custom_skill.strip())

def process_single_resume(args):
    """Process a single resume with a specific API key"""
    idx, row, api_key, all_skills = args
    
    try:
        llm_instance = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
        
        resume = " ".join([str(row[col]) for col in row.index]) 
        required_experience_desc = "Ø³Ø§Ø¨Ù‚Ù‡ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ÛŒ" 
        universities = universities_info 
        major_list = []
        job_profile_title = ""
        volunteering_field = row.get("ÙØ¹Ø§Ù„ÛŒØª Ø¯Ø§ÙˆØ·Ù„Ø¨Ø§Ù†Ù‡", "") 
        about_me_field = row.get("Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ù†", "")

        results = scoring_chain(
            resume, 
            all_skills, 
            required_experience_desc, 
            universities, 
            major_list, 
            job_profile_title, 
            volunteering_field, 
            about_me_field
        )

        row_data = row.to_dict()
        row_data['Ø±Ø¯ÛŒÙ'] = idx + 1
        for agent, detail in results.items():
            if agent != "FinalScore":
                row_data[f"{agent}_score"] = detail['score']
                row_data[f"{agent}_reason"] = detail['reason']
        row_data['final_score'] = results['FinalScore']
        row_data['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] = "ØªØ§ÛŒÛŒØ¯" if row_data['final_score'] >= 70 else "Ø±Ø¯"
        
        return (idx, row_data, None)
    
    except Exception as e:
        return (idx, None, str(e))

if uploaded_file:
    df = pd.read_excel(uploaded_file, skiprows=2)
    
    st.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡: {len(df)} | ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {len(df.columns)}")
    
    with st.expander("Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"):
        st.dataframe(df.head())
    
    stage = st.radio("ğŸ§© Ù…Ø±Ø­Ù„Ù‡ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:", ["Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ", "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"])

    if stage == "Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ": 
        st.markdown("### ğŸš€ Ù…Ø±Ø­Ù„Ù‡ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§") 
        
        max_workers = min(len(API_KEYS), len(df))
        st.info(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ {max_workers} API Key Ø¨Ø±Ø§ÛŒ {len(df)} Ø±Ø²ÙˆÙ…Ù‡")
        
        if st.button("Ø´Ø±ÙˆØ¹ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ"): 
            results_placeholder = st.empty() 
            progress_bar = st.progress(0) 
            rows = [None] * len(df)
            completed = 0
            
            processing_args = [
                (idx, row, API_KEYS[idx % len(API_KEYS)], all_skills)
                for idx, (_, row) in enumerate(df.iterrows())
            ]
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_idx = {
                    executor.submit(process_single_resume, args): args[0] 
                    for args in processing_args
                }
                
                for future in concurrent.futures.as_completed(future_to_idx):
                    idx, row_data, error = future.result()
                    
                    if error:
                        st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø²ÙˆÙ…Ù‡ Ø±Ø¯ÛŒÙ {idx + 1}: {error}")
                        row_data = df.iloc[idx].to_dict()
                        row_data['Ø±Ø¯ÛŒÙ'] = idx + 1
                        row_data['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] = "Ø®Ø·Ø§"
                        row_data['final_score'] = 0
                    
                    rows[idx] = row_data
                    completed += 1
                    
                    progress_bar.progress(completed / len(df))
                    
                    current_results = [r for r in rows if r is not None]
                    if current_results:
                        temp_df = pd.DataFrame(current_results)
                        results_placeholder.dataframe(temp_df)
                    
                    live_df = pd.DataFrame(current_results)
                    total = len(df)
                    checked = len(live_df)
                    accepted = (live_df['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] == 'ØªØ§ÛŒÛŒØ¯').sum() if 'ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡' in live_df.columns else 0
                    failed = (live_df['ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡'] != 'ØªØ§ÛŒÛŒØ¯').sum() if 'ØªØ§ÛŒÛŒØ¯ Ùˆ Ø±Ø¯ Ø§ÙˆÙ„ÛŒÙ‡' in live_df.columns else 0
                    
                    status_placeholder.success(f"Ø¨Ø±Ø±Ø³ÛŒ Ø´Ø¯Ù‡: {checked} / {total}")
                    status_placeholder.markdown(f"ğŸŸ¢ Ù‚Ø¨ÙˆÙ„â€ŒØ´Ø¯Ù‡: {accepted}")
                    status_placeholder.markdown(f"ğŸ”´ Ø±Ø¯â€ŒØ´Ø¯Ù‡: {failed}")
                    progress_placeholder.progress(checked / total)
            
            results_df = pd.DataFrame(rows)
            results_placeholder.dataframe(results_df)
            results_df.to_excel("resume_scoring.xlsx", index=False)
            style_excel("resume_scoring.xlsx")

            st.success("âœ… Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

            with open("resume_scoring.xlsx", "rb") as f:
                st.download_button(
                    label="ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ",
                    data=f,
                    file_name="resume_scoring.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

    elif stage == "ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ":
        st.markdown("### ğŸ” Ù…Ø±Ø­Ù„Ù‡ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ")
        results_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        max_workers = min(len(API_KEYS), len(df))
        st.info(f"Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ {max_workers} API Key Ø¨Ø±Ø§ÛŒ {len(df)} Ø±Ø²ÙˆÙ…Ù‡")

        if st.button("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ"):
            try:
                def process_single_matching(args):
                    """Process job matching for a single resume"""
                    idx, row, api_key = args
                    try:
                        resume_text = " ".join([str(row[col]) for col in row.index])
                        
                        prompt = f"""Ø´Ù…Ø§ ÛŒÚ© Ø§Ø±Ø²ÛŒØ§Ø¨ Ù…Ù†Ø§Ø¨Ø¹ Ø§Ù†Ø³Ø§Ù†ÛŒ Ù‡Ø³ØªÛŒØ¯. Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø±Ø²ÙˆÙ…Ù‡ Ø²ÛŒØ±ØŒ Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù‡Ø± ÛŒÚ© Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ ØªØ¹Ø±ÛŒÙâ€ŒØ´Ø¯Ù‡ØŒ ÛŒÚ© Ø¯Ø±ØµØ¯ ØªØ·Ø§Ø¨Ù‚ Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û° Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ ÛŒÚ© Ø¯Ù„ÛŒÙ„ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ø°Ú©Ø± Ú©Ù†ÛŒØ¯.

Ø±Ø²ÙˆÙ…Ù‡:
{resume_text}

Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ù‡ ØµÙˆØ±Øª JSON Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
[
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø§ÙˆÙ„",
    "match_percent": 85,
    "reason": "ØªÙˆØ¶ÛŒØ­ Ø¯Ù„ÛŒÙ„ ØªØ·Ø§Ø¨Ù‚ ÛŒØ§ Ø¹Ø¯Ù… ØªØ·Ø§Ø¨Ù‚"
  }},
  {{
    "title": "Ø¹Ù†ÙˆØ§Ù† Ø´ØºÙ„ Ø¯ÙˆÙ…",
    "match_percent": 45,
    "reason": "..."
  }}
  ...
]
Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ:
{json.dumps(JOB_PROFILES, ensure_ascii=False)}
"""
                        
                        client = genai.Client(api_key=api_key)
                        response = client.models.generate_content(
                            model="gemini-2.5-flash",
                            contents=prompt,
                            config={
                                "response_mime_type": "application/json",
                                "temperature": 0
                            }
                        )
                        
                        json_text = response.candidates[0].content.parts[0].text.strip()
                        parsed = json.loads(json_text)
                        match_df = pd.DataFrame(parsed)
                        
                        match_df["Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡"] = idx + 1
                        match_df["Ù†Ø§Ù…"] = row.get("Ù†Ø§Ù…", "")
                        match_df["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"] = row.get("Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ", "")
                        
                        return (idx, match_df, None)
                    except Exception as e:
                        return (idx, None, str(e))
                
                processing_args = [
                    (idx, row, API_KEYS[idx % len(API_KEYS)])
                    for idx, (_, row) in enumerate(df.iterrows())
                ]
                
                all_results = [None] * len(df)
                completed = 0
                
                with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
                    future_to_idx = {
                        executor.submit(process_single_matching, args): args[0]
                        for args in processing_args
                    }
                    
                    for future in concurrent.futures.as_completed(future_to_idx):
                        idx, match_df, error = future.result()
                        
                        if error:
                            st.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªØ·Ø¨ÛŒÙ‚ Ø±Ø²ÙˆÙ…Ù‡ Ø±Ø¯ÛŒÙ {idx + 1}: {error}")
                        else:
                            all_results[idx] = match_df
                        
                        completed += 1
                        progress_bar.progress(completed / len(df))
                
                match_results = pd.concat([r for r in all_results if r is not None], ignore_index=True)
                
                def make_sentence(row):
                    return f"Ù…ÛŒØ²Ø§Ù† Ø§Ù†Ø·Ø¨Ø§Ù‚ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ {row['title']} {int(row['match_percent'])}Ùª Ø§Ø³ØªØŒ Ø²ÛŒØ±Ø§: {row['reason']}"

                grouped = match_results.groupby("Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡")

                final_rows = []
                for resume_row_num, group in grouped:
                    name = group["Ù†Ø§Ù…"].iloc[0]
                    family = group["Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ"].iloc[0]
                    sentences = [make_sentence(row) for _, row in group.iterrows()]
                    full_text = "  ".join(sentences)
                    best_row = group.loc[group["match_percent"].idxmax()]
                    best_title = best_row["title"]

                    final_rows.append({
                        "Ø±Ø¯ÛŒÙ Ø±Ø²ÙˆÙ…Ù‡": resume_row_num,
                        "Ù†Ø§Ù…": name,
                        "Ù†Ø§Ù… Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ": family,
                        "Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´ØºÙ„ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ": best_title,
                        "ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ": full_text
                    })

                summary_df = pd.DataFrame(final_rows)

                summary_path = "job_matching_summary.xlsx"
                summary_df.to_excel(summary_path, index=False)
                style_excel(summary_path)

                st.success("âœ… ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ù†Ø§Ø³Ù†Ø§Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ØºÙ„ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
                st.dataframe(summary_df)

                with open(summary_path, "rb") as f:
                    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ØªØ­Ù„ÛŒÙ„â€ŒØ´Ø¯Ù‡", f, file_name=summary_path)

                progress_bar.progress(1.0)
            
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… ØªØ·Ø¨ÛŒÙ‚: {e}")

if RESULT_FILE_PATH.exists():
    final_df = pd.read_excel(RESULT_FILE_PATH)

    display_df = final_df.copy()
    display_df.index = display_df.index + 1
    display_df.index.name = "Ø±Ø¯ÛŒÙ"

    st.markdown("### âœ… Ø¬Ø¯ÙˆÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒØ´Ø¯Ù‡")
    
    if 'score' in display_df.columns:
        styled_df = display_df.style.applymap(color_score_column, subset=['score'])
        st.dataframe(styled_df)
    else:
        st.dataframe(display_df)

    style_excel(RESULT_FILE_PATH)
    with open(RESULT_FILE_PATH, "rb") as f:
        st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ", f, file_name="resume_results.xlsx")



