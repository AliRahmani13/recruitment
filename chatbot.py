import streamlit as st
import fitz  # PyMuPDF
import json
import os
import re
from datetime import datetime
import pandas as pd
from google.generativeai import types as genai_types
import google.generativeai as genai
from pathlib import Path

# --- Global Configurations & Constants ---
PROXY_URL = os.getenv("APP_HTTP_PROXY", "http://172.16.217.234:33525")
if PROXY_URL:
    os.environ['HTTP_PROXY'] = PROXY_URL
    os.environ['HTTPS_PROXY'] = PROXY_URL

# --- CORRECTED API KEY HANDLING ---
# The API key is now assigned directly to the variable.
# This is the simplest way to get the application running for testing.
GEMINI_API_KEY = "AIzaSyBEZ9d7p008FjBDcw_bLWL-328AX7rAng0"

DEFAULT_REQUEST_OPTIONS = {
    "generation_config": {
        "temperature": 0.6,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 1024
    }
}

JOB_PROFILES = {
    "ฺฉุงุฑุดูุงุณ ุชุญููฺฏุฑ ุฏุงุฏู": "job_analysis_01",
    "ฺฉุงุฑุดูุงุณ ุชุญูู ู ุชูุณุนู ุณุงูุงูู ูุง": "job_rnd_01",
    "ฺฉุงุฑุดูุงุณ ุชุญูู ู ุชูุณุนู": "job_research_01",
    "ุชูุณุนู ุฑุงูฺฉุงุฑูุง ูุจุชู ุจุฑ ููุด ูุตููุน": "job_ai_01",
    "ุชูุณุนู ุฑุงูฺฉุงุฑูุง ุชุญูู ุงุทูุงุนุงุช ูฺฉุงู": "job_spatial_01"
}
DOWNLOADS_DIR_NAME = "chatbotResult_v3"
DEFAULT_USER_NAME = "ฺฉุงุฑุจุฑ ูุญุชุฑู"
MAX_DYNAMIC_QUESTIONS = os.getenv("MAX_DYNAMIC_QUESTIONS", 7)
SALARY_THRESHOLD = 60000000

# --- Helper Functions ---

def configure_api():
    """
    Configures the Google Generative AI client with the API key.
    Reads the key from the global variable 'GEMINI_API_KEY'.
    Returns True on success, False on failure.
    """
    if GEMINI_API_KEY and len(GEMINI_API_KEY) > 30: # Basic check for a valid-looking key
        try:
            genai.configure(api_key=GEMINI_API_KEY)
            # st.success("โ ูพฺฉุฑุจูุฏ API ุจุง ููููุช ุงูุฌุงู ุดุฏ.") # Optional: uncomment for successful confirmation
            return True
        except Exception as e:
            st.error(f"โ ุฎุทุง ูพฺฉุฑุจูุฏ API: ฺฉูุฏ ูุงุฑุฏ ุดุฏู ูุงูุนุชุจุฑ ุจู ูุธุฑ ูโุฑุณุฏ. {e}")
            return False
    else:
        st.error("โ ฺฉูุฏ API (GEMINI_API_KEY) ุฏุฑ ฺฉุฏ ุชูุธู ูุดุฏู ุง ูุงูุนุชุจุฑ ุงุณุช.")
        st.markdown("ูุทูุงู ฺฉ ฺฉูุฏ ูุนุชุจุฑ ุฏุฑ ุฎุท ฒฑ ูุงู ฺฉุฏ ูุงุฑุฏ ฺฉูุฏ.")
        return False

def generate_screening_question(q_id: str, resume_text: str) -> str:
    if q_id == "salary":
        salary, _ = extract_salary_range(resume_text)
        if salary:
            return f"ุฏุฑ ุฑุฒููู ุดูุง ุญููู ุฏุฑุฎูุงุณุช ยซ{salary}ยป ุซุจุช ุดุฏู. ุฏุฑุณุชูุ ููฺูู ูุทูุงู ุญุฏุงูู ุญููู ูุฏูุธุฑุชุงู ุฑุง ูู ุจููุณุฏ."
        return "ุญููู ุฏุฑุฎูุงุณุช ุดูุง ุฏุฑ ุฑุฒููู ุฐฺฉุฑ ูุดุฏู. ุญุฏูุฏ ุญุฏุงูู ูุฏูุธุฑุชุงู ุฑุง ุจูุฑูุงุฏ."
    elif q_id == "military":
        status = extract_military_status(resume_text)
        if status:
            return f"ุฏุฑ ุฑุฒููู ููุดุชู ุดุฏู ูุถุนุช ูุธุงู ูุธูู ุดูุง ยซ{status}ยป ุงุณุช. ุงฺฏุฑ ุฏุฑุณุชู ุชุฃุฏ ุจูุฑูุงุฏุ ูฺฏุฑูู ุงุตูุงุญ ฺฉูุฏ."
        return "ูุทูุงู ูุถุนุช ูุธุงู ูุธูู ุฎูุฏ ุฑุง ูุดุฎุต ฺฉูุฏ (ูุซูุงู: ูพุงุงู ุฎุฏูุชุ ูุนุงูุชุ ูุดููู ู...)"
    elif q_id == "availability":
        level = extract_education_level(resume_text)
        student = extract_student_status(resume_text)
        parts = []
        if level: parts.append(f"ูุฏุฑฺฉ ุชุญุตู: ยซ{level}ยป")
        if student: parts.append(f"ูุถุนุช ุฏุงูุดุฌู: ยซ{student}ยป")
        if parts:
            return "ุฏุฑ ุฑุฒููู " + " ู ".join(parts) + " ุขูุฏู ุงุณุช. ุงฺฏุฑ ุตุญุญ ุงุณุช ุชุฃุฏ ฺฉูุฏ ู ุงฺฏุฑ ุชูุถุญ ุจุดุชุฑ ูุณุช ุจูุฑูุงุฏ."
        return "ูุทูุงู ูุถุนุช ุชุญุตู ู ุชุนุฏุงุฏ ุฑูุฒูุง ฺฉู ูโุชูุงูุฏ ุฏุฑ ููุชู ุญุถูุฑ ุฏุงุดุชู ุจุงุดุฏ ุฑุง ุจููุณุฏ."
    return "ูุทูุงู ูพุงุณุฎ ุงู ุณูุงู ุฑุง ุจูุฑูุงุฏ."

def extract_salary_range(resume_text: str) -> tuple[str | None, str]:
    match = re.search(r'(\d{1,3}(?:[,ุ]?\d{3})*)\s*(?:ุชุง|-|~)\s*(\d{1,3}(?:[,ุ]?\d{3})*)\s*(?:ุชููุงู|ุฑูุงู)?', resume_text)
    if match:
        min_val = match.group(1).replace(',', '').replace('ุ', '')
        max_val = match.group(2).replace(',', '').replace('ุ', '')
        return f"{int(min_val):,} ุชุง {int(max_val):,} ุชููุงู", ""
    return None, "ุฏุฑ ุฑุฒููู ุฐฺฉุฑ ูุดุฏู."

def extract_military_status(resume_text: str) -> str | None:
    options = ["ูพุงุงู ุฎุฏูุช", "ูุนุงูุช", "ูุดููู", "ุฏุฑ ุญุงู ุฎุฏูุช", "ุงูุฑู"]
    for opt in options:
        if opt in resume_text: return opt
    return None

def extract_education_level(resume_text: str) -> str | None:
    for degree in ["ุฏูพูู", "ููู ุฏูพูู", "ฺฉุงุฑุฏุงู", "ฺฉุงุฑุดูุงุณ", "ฺฉุงุฑุดูุงุณ ุงุฑุดุฏ", "ุฏฺฉุชุฑ"]:
        if degree in resume_text: return degree
    return None

def extract_student_status(resume_text: str) -> str | None:
    if "ุฏุงูุดุฌู" in resume_text:
        presence_match = re.search(r"(?:\d{1,2})\s*(?:ุฑูุฒ|ุณุงุนุช)", resume_text)
        return presence_match.group(0) if presence_match else "ุงุทูุงุนุงุช ูุงูุต"
    return None

def extract_age(resume_text: str) -> str | None:
    match = re.search(r"(?:ุณู\s*[:\-]?\s*)(\d{2})", resume_text)
    return match.group(1) if match else None

def extract_structured_response(text: str, default_feedback: str = "ูุชุดฺฉุฑู.", default_question: str = None) -> dict:
    json_text = ""
    try:
        code_block_match = re.search(r"```(?:json)?\s*(\{[\s\S]*?\})\s*```", text, re.DOTALL)
        if code_block_match: json_text = code_block_match.group(1)
        else:
            object_match = re.search(r"(\{[\s\S]*?\})", text, re.DOTALL)
            if object_match: json_text = object_match.group(1)
            else:
                if len(text.splitlines()) <= 2 and "?" in text: return {"feedback": None, "next_question": text.strip()}
                return {"feedback": text.strip(), "next_question": default_question, "error": "Non-JSON response"}

        if not json_text: return {"feedback": text.strip() if text.strip() else default_feedback, "next_question": default_question, "error":"Empty JSON extracted"}
        parsed_json = json.loads(json_text)
        if not isinstance(parsed_json, dict): return {"feedback": f"ูพุงุณุฎ ุบุฑููุชุธุฑู: {str(parsed_json)}", "next_question": default_question, "error":"JSON is not a dict"}

        feedback = parsed_json.get("feedback")
        next_q = parsed_json.get("next_question")

        if next_q is None and not parsed_json.get("end_interview"):
            return {"feedback": feedback or default_feedback, "next_question": None, "error": "LLM provided null next_question without ending interview.", "end_interview": True}

        return {"feedback": feedback, "next_question": next_q, "end_interview": parsed_json.get("end_interview", False)}
    except Exception as e:
        return {"feedback": f"ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด ูพุงุณุฎ (ุณุงุฎุชุงุฑ ููุฑุฏ ุงูุชุธุงุฑ: JSON): {str(e)[:100]}...", "next_question": default_question, "error": f"Exception: {str(e)}", "end_interview": True}

def clean_excel_text(text) -> str:
    text_str = str(text) if isinstance(text, (list, dict)) else str(text)
    return ''.join(c for c in text_str if c.isprintable())

def extract_name_from_resume(resume_text: str) -> str:
    lines = resume_text.strip().splitlines()
    if not lines:
        return DEFAULT_USER_NAME

    for line in lines[:5]:
        clean_line = line.strip()
        if 3 < len(clean_line) < 40 and all(c.isalpha() or c.isspace() or c in "ุขุงุจูพุชุซุฌฺุญุฎุฏุฐุฑุฒุณุดุตุถุทุธุนุบููฺฉฺฏูููููโ " for c in clean_line):
            return clean_line
    return DEFAULT_USER_NAME

FIXED_SCREENING_QUESTIONS = [
    {"id": "salary", "text": "ุญููู ุฏุฑุฎูุงุณุช ูุฏ ูุธุฑ ุดูุง ุจุฑุง ุงู ูููุนุช ุดุบู ุญุฏูุฏุงู ฺูุฏุฑ ุงุณุชุ (ุจู ุชููุงู)"},
    {"id": "availability", "text": "ุขุง ุฏุฑ ุญุงู ุญุงุถุฑ ุฏุงูุดุฌู ูุณุชุฏุ ุฏุฑ ุตูุฑุช ูุซุจุช ุจูุฏูุ ูุทูุงู ุฏุฑ ููุฑุฏ ูุถุนุช ุชุญุตู ู ูุฒุงู ุณุงุนุช ุญุถูุฑ ุฏุฑ ููุชู ฺฉู ุงูฺฉุงู ููฺฉุงุฑ ุฏุงุฑุฏุ ุชูุถุญ ุฏูุฏ."},
    {"id": "military", "text": "ูุถุนุช ูุธุงู ูุธูู ุดูุง ฺฺฏููู ุงุณุชุ (ูพุงุงู ุฎุฏูุชุ ูุนุงูุช ุฏุงุฆูุ ูุนุงูุช ุชุญุตูุ ุฏุฑ ุญุงู ุฎุฏูุชุ ูุดููู ู ุบุฑู)"}
]

def initialize_session_state():
    defaults = {
        "user_name": DEFAULT_USER_NAME, "user_id": None,
        "resume_text": "", "selected_job": None, "selected_job_id": None,
        "interview_stage": "initial_setup",
        "conversation_history": [],
        "screening_questions_list": FIXED_SCREENING_QUESTIONS.copy(),
        "current_screening_q_idx": 0,
        "screening_answers": [],
        "screening_passed": None,
        "dynamic_question_count": 0,
        "max_dynamic_questions": int(MAX_DYNAMIC_QUESTIONS),
        "ai_is_processing": False,
        "screening_conversation": [],
        "current_screening_question": None,
        "awaiting_screening_answer": False

    }
    for key, value in defaults.items():
        if key not in st.session_state: st.session_state[key] = value

def reset_for_new_interview():
    current_user_name = st.session_state.get("user_name", DEFAULT_USER_NAME)
    st.session_state.clear(); initialize_session_state()
    if current_user_name != DEFAULT_USER_NAME: st.session_state.user_name = current_user_name

def process_uploaded_file(uploaded_file_obj) -> str:
    if not uploaded_file_obj: return ""
    if uploaded_file_obj.size == 0: st.warning("โ๏ธ ูุงู ุขูพููุฏ ุดุฏู ุฎุงู ุงุณุช."); return ""
    text_content = ""
    try:
        if uploaded_file_obj.name.endswith(".txt"): text_content = uploaded_file_obj.read().decode("utf-8")
        elif uploaded_file_obj.name.endswith(".pdf"):
            doc = fitz.open(stream=uploaded_file_obj.read(), filetype="pdf")
            for page in doc: text_content += page.get_text("text")
            if not text_content.strip() and doc.page_count > 0: st.warning("โ๏ธ ุฑุฒููู PDF ูพุฑุฏุงุฒุด ูุดุฏ (ููฺฉู ุงุณุช ุงุณฺฉู ุดุฏู ุจุงุดุฏ).")
        return text_content.strip()
    except Exception as e: st.error(f"โ ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด ูุงู ุฑุฒููู: {e}")
    return ""

def run_initial_screening(answers_list: list) -> tuple[bool, str]:
    salary_answer_text = ""; availability_answer_text = ""; military_answer_text = ""
    for item in answers_list:
        q_id = item['question_id']; ans_text = item['answer'].lower()
        if q_id == "salary": salary_answer_text = ans_text
        elif q_id == "availability": availability_answer_text = ans_text
        elif q_id == "military": military_answer_text = ans_text
    try:
        salary_numbers = [int(s) for s in re.findall(r'\d+', salary_answer_text.replace(',', '').replace('ุชููุงู','').strip())]
        if salary_numbers and max(salary_numbers) > SALARY_THRESHOLD:
            return False, f"ุจุง ุณูพุงุณุ ูุนูุงู ุดุฑุงุท ููฺฉุงุฑ ุจุง ุญููู ุฏุฑุฎูุงุณุช ุดูุง (ุจุด ุงุฒ {SALARY_THRESHOLD:,} ุชููุงู) ูุฑุงูู ูุณุช."
    except: pass
    if "ุฏุงูุดุฌู ูุณุชู" in availability_answer_text or "ุฏุงูุดุฌูุงู" in availability_answer_text:
        if any(word in availability_answer_text for word in ["ุณู ุฑูุฒ", "ฺูุงุฑ ุฑูุฒ", "ุจุดุชุฑ ุงุฒ ุฏู", "ูุญุฏูุฏุช ุฒุงุฏ", "ููโุชูุงูู ุชูุงู ููุช", "ูุตู ุฑูุฒ"]):
            return False, "ุจุง ุณูพุงุณุ ูุนูุงู ุงูฺฉุงู ููฺฉุงุฑ ุจุง ุชูุฌู ุจู ูุญุฏูุฏุช ุญุถูุฑ ุดูุง (ุฏุงูุดุฌู) ูุฑุงูู ูุณุช."
    if any(word in military_answer_text for word in ["ุงูุฑู", "ูุดููู", "ุณุฑุจุงุฒู", "ุฏุฑ ุญุงู ุฎุฏูุช", "ุณุฑุจุงุฒ ูุฑูุชู"]):
        resume_lower = st.session_state.get("resume_text", "").lower()
        if not any(exc in resume_lower for exc in ["ูพุงุงู ุฎุฏูุช", "ูุนุงูุช ุฏุงุฆู", "ูุนุงูุช ูพุฒุดฺฉ"]):
            return False, "ุจุง ุณูพุงุณุ ูุชุงุณูุงูู ุดุฑฺฉุช ุงูฺฉุงู ุฌุฐุจ ูุฑู ุงูุฑู ุง ูุดููู ุฑุง ูุฏุงุฑุฏ."
    return True, "ุบุฑุจุงูฺฏุฑ ุงููู ุจุง ููููุช ุงูุฌุงู ุดุฏ. ุจู ูุฑุญูู ุจุนุฏ ฺฏูุชฺฏู ุชุฎุตุตโุชุฑ ูโุฑูู."

def get_next_ai_turn(conversation_history, resume_text, job_profile, user_name) -> dict:
    st.session_state.ai_is_processing = True
    persona_definition = f"""
    ุดูุง ููุงูุฏูโ ุฑุณู ุดุฑฺฉุช ยซุฏุงุฏูโูพุฑุฏุงุฒุงู ุจูุงู ุขูุงยป ูุณุชุฏ. ูุธููโ ุดูุง ุงูุฌุงู ฺฉ ูุตุงุญุจู ุญุฑููโุง ููุงุจุน ุงูุณุงู ุจุง ุฌูุงุจ {user_name} ุจุฑุง ูููุนุช ุดุบู ยซ{job_profile}ยป ูโุจุงุดุฏ.
    ุงู ูุตุงุญุจู ุจุง ุชูุฑฺฉุฒ ุจุฑ ุงุฑุฒุงุจ ููุงุฑุชโูุง ูุฑู ู ุดุงุณุชฺฏโูุง ุฑูุชุงุฑ ูุงูุจุฑุฏู ุงูุฌุงู ูโฺฏุฑุฏ.
    ุดูุง ุจุงุฏ ูุตุงุญุจู ุฑุง ุจู ุดฺฉู ุฑูุงูุ ูุญุชุฑูุงููุ ุงูุณุงู ู ููุฏูุงูู ูพุด ุจุจุฑุฏ ุชุง ุดูุงุฎุช ุฏูู ุงุฒ ูฺฺฏโูุง ูุฑุฏุ ูฺฏุฑุดโูุงุ ุชูุงูููุฏโูุง ู ุณุจฺฉ ุชุนุงูู ุงุดุงู ุจูโุฏุณุช ุขูุฑุฏ.

    ุดูุง ููโุชููุง ูุตุงุญุจูโฺฏุฑ ูุณุชุฏุ ุจูฺฉู ููุด ูุงุธุฑ ููุงุจุน ุงูุณุงู ุฑุง ูุฒ ุจุฑ ุนูุฏู ุฏุงุฑุฏ ู ุจุงุฏ ูุฑ ูุฑุญูู ุงุฒ ฺฏูุชฺฏู ุฑุง ุจุง ุฏูุช ุชุญูู ู ูุฏุงุช ฺฉูุฏ.
    ุงุฒ ฺฉููุงุช ูู ู ุงุฏุจ ููุงุณุจ ุงุณุชูุงุฏู ฺฉูุฏ ู ุฏุฑ ุจุฑุฎูุฑุฏ ุจุง ฺฉุงุฑุจุฑุ ุงุญุชุฑุงูุ ุฏูุชุ ู ุฑูุชุงุฑ ุญุฑููโุง ุฑุง ุญูุธ ููุงุฏ.
    """
    core_instructions = """\
ูุธุงู ุดูุง ุฏุฑ ูุฑ ููุจุช ฺฏูุชฺฏู:
1.  **ุชุญูู ูพุงุณุฎ ูุจู:** ูพุงุณุฎ ุขุฎุฑ ฺฉุงุฑุจุฑ ุฑุง ุจู ุฏูุช ุชุญูู ฺฉูุฏ. (ุงฺฏุฑ ุงููู ุณูุงู ุดูุง ูพุณ ุงุฒ ุบุฑุจุงูฺฏุฑ ุงุณุชุ ุงุฒ ุงู ูุฑุญูู ุตุฑู ูุธุฑ ฺฉุฑุฏู ู ูุณุชููุงู ุจู ุทุฑุญ ุณูุงู ุจุฑูุฏ).
2.  **ุงุฑุงุฆู ุจุงุฒุฎูุฑุฏ (ฺฉูุชุงู ู ุทุจุน):** ฺฉ ุจุงุฒุฎูุฑุฏ ฺฉูุชุงูุ ุฏูุณุชุงูู ู ูุฑุชุจุท ุจู ูพุงุณุฎ ฺฉุงุฑุจุฑ ุจุฏูุฏ. ูุซูุงู: "ูุชูุฌู ุดุฏู."ุ "ูฺฉุชู ุฌุงูุจ ุจูุฏ."ุ "ููููู ุงุฒ ุชูุถุญุชูู." ุง ุชุงุฏ ฺฉูุชุงู ุจุฑ ูุญุชูุง ูพุงุณุฎ. (ุงฺฏุฑ ุงููู ุณูุงู ูพุณ ุงุฒ ุบุฑุจุงูฺฏุฑ ุงุณุชุ ุงู ุจุฎุด ุฑุง ุจุง ฺฉ ุฌููู ุฎูุดุงูุฏฺฏู ู ูุนุฑู ุดุฑูุน ฺฏูุชฺฏู ุฌุงฺฏุฒู ฺฉูุฏุ ูุซูุง: "ุนุงู ุจูุฏ ฺฉู ุงุฒ ูุฑุญูู ุบุฑุจุงูฺฏุฑ ุนุจูุฑ ฺฉุฑุฏุฏ! ุญุงูุง ูโุฎูุงูู ฺฉู ุนููโุชุฑ ุฏุฑ ููุฑุฏ ุชุฌุฑุจุงุช ู ุฑูฺฉุฑุฏูุง ุดูุง ุตุญุจุช ฺฉูู.").
3.  **ุทุฑุญ ุณูุงู ุจุนุฏ (ููุดููุฏุงูู ู ุนูู):**
    * ฺฉ ุณูุงู ุจุงุฒ ู ูุฑุชุจุท ุจุง ูพุงุณุฎ ูุจู ฺฉุงุฑุจุฑ ุง ุฌูุจูโุง ุฌุฏุฏ ุงุฒ ููุงุฑุชโูุง ูุฑู ุงู ุทุฑุงุญ ฺฉูุฏ. ุณูุงูุงุช ุจุงุฏ ุจู ฺฏูููโุง ุจุงุดูุฏ ฺฉู ฺฉุงุฑุจุฑ ุฑุง ุจู ูฺฉุฑ ูุงุฏุงุฑ ฺฉุฑุฏู ู ุงู ุฑุง ุชุดูู ุจู ุงุฑุงุฆู ูุซุงูโูุง ูุงูุน ุงุฒ ุชุฌุฑุจุงุชุด ฺฉูุฏ.
    * **ููุงุฑุชโูุง ูุฑู ฺฉูุฏ ุจุฑุง ุงุฑุฒุงุจ (ูุชูุงุณุจ ุจุง ุดุบู '{job_profile}'):** ุชูุฑฺฉุฒ ุจุฑ ุฑู (ุงูุง ูู ูุญุฏูุฏ ุจู):
        * **ุญู ูุณุฆูู ู ุชูฺฉุฑ ุงูุชูุงุฏ:** ูุญูู ููุงุฌูู ุจุง ฺุงูุดโูุงุ ุชุญูู ูููุนุชุ ุชุตููโฺฏุฑ.
        * **ููุงุฑุชโูุง ุงุฑุชุจุงุท:** ูุถูุญ ฺฉูุงูุ ูู ุจุงูุ ุดูุฏู ูุนุงูุ ููุฏู.
        * **ฺฉุงุฑ ุชู ู ููฺฉุงุฑ:** ุชุฌุฑุจุงุช ฺฉุงุฑ ุจุง ุฏฺฏุฑุงูุ ูุฏุฑุช ุชุนุงุฑุถุ ููุด ุฏุฑ ุชู.
        * **ุงูุทุจุงูโูพุฐุฑ ู ูุฏุฑุช ุชุบุฑ:** ูุงฺฉูุด ุจู ุดุฑุงุท ุฌุฏุฏุ ุงูุนุทุงูโูพุฐุฑ.
        * **ุงุจุชฺฉุงุฑ ู ุฎูุฏุงูฺฏุฎุชฺฏ:** ูุณุฆููุชโูพุฐุฑุ ุงุฑุงุฆู ุฑุงูฺฉุงุฑุ ุงุดุชุงู ุจู ุจูุจูุฏ.
        * **ูุฏุฑุช ุงุณุชุฑุณ ู ุชุงุจโุขูุฑ:** ูุญูู ุจุฑุฎูุฑุฏ ุจุง ูุดุงุฑ ู ุดฺฉุณุช.
        * **ุงุฏฺฏุฑ ู ฺฉูุฌฺฉุงู:** ุชูุงู ุจู ุฑุดุฏุ ุงุฏฺฏุฑ ุงุฒ ุจุงุฒุฎูุฑุฏ.
        * **ุงุฎูุงู ุญุฑููโุง ู ูุณุฆููุชโูพุฐุฑ:** ุชุนูุฏ ุจู ฺฉุงุฑุ ุตุฏุงูุช.
    * ุงุฒ ูพุฑุณุฏู ุณูุงูุงุช ุชฺฉุฑุงุฑ ุง ุณูุงูุงุช ฺฉู ูพุงุณุฎ ฺฉูุชุงู "ุจูู/ุฎุฑ" ุฏุงุฑูุฏุ ุงฺฉุฏุงู ุฎูุฏุฏุงุฑ ฺฉูุฏ.
    * ูุญู ุดูุง ุจุงุฏ ุญุฑููโุงุ ุจุณุงุฑ ุฏูุณุชุงููุ ฺฉูุฌฺฉุงูุ ููุฏูุงูู ู ุฑูุงูุดูุงุณุงูู ุจุงุดุฏ. ูุงู ฺฉุงุฑุจุฑ ({user_name}) ุฑุง ฺฏุงู ุฏุฑ ุตุญุจุชโูุง ุฎูุฏ ุจู ฺฉุงุฑ ุจุจุฑุฏ.
ูุญุฏูุฏุชโูุง ู ูุญูู ูพุงุงู ุฏุงุฏู:
* ุชุนุฏุงุฏ ฺฉู ุณูุงูุงุช ูพูุง ุฏุฑ ุงู ุจุฎุด ({st.session_state.max_dynamic_questions - st.session_state.dynamic_question_count} ุณูุงู ุฏฺฏุฑ ุจุงู ูุงูุฏู). ุดูุง ุชุตูู ูโฺฏุฑุฏ ฺู ุฒูุงู ุงุทูุงุนุงุช ฺฉุงู ุจุฑุง ุงุฑุฒุงุจ ุงููู ฺฉุณุจ ฺฉุฑุฏูโุงุฏ.
* ุงฺฏุฑ ุชุดุฎุต ุฏุงุฏุฏ ฺฉู ุจู ุงูุฏุงุฒู ฺฉุงู ุงุทูุงุนุงุช ฺฉุณุจ ุดุฏู ุง ุจู ุณูู ุณูุงูุงุช ุฑุณุฏูโุงุฏุ ูุตุงุญุจู ุงู ุจุฎุด ุฑุง ุจุง ฺฉ ูพุงู ุชุดฺฉุฑ ููุงุณุจ ูพุงุงู ุฏูุฏ.
ุฎุฑูุฌ ุงูุฒุงู (ูุฑูุช JSON ุฏููุงู ุจู ุงู ุดฺฉู):
```json
{{
  "feedback": "ุจุงุฒุฎูุฑุฏ ุดูุง ุฏุฑ ุงูุฌุง ุง null ุงฺฏุฑ ุงููู ุณูุงู ูพุณ ุงุฒ ุบุฑุจุงูฺฏุฑ ุงุณุช",
  "next_question": "ุณูุงู ุจุนุฏ ุดูุง ุฏุฑ ุงูุฌุงุ ุง null ุงฺฏุฑ ูุตุงุญุจู ุงู ุจุฎุด ุชูุงู ุดุฏู ุจุงุดุฏ",
  "end_interview": false
}}
```
ูุซุงู ุจุฑุง ุงููู ุณูุงู ูพุณ ุงุฒ ุบุฑุจุงูฺฏุฑ: {{"feedback": "ุฎุจ {user_name} ุนุฒุฒุ ุงุฒ ุงูฺฉู ุชุง ุงู ูุฑุญูู ููุฑุงู ูุง ุจูุฏุฏ ูููููู. ุญุงูุง ูโุฎูุงูู ฺฉู ุนููโุชุฑ ุฏุฑ ููุฑุฏ ุชุฌุฑุจุงุช ู ูุญูู ุฑูฺฉุฑุฏ ุดูุง ุจู ูุณุงุฆู ุตุญุจุช ฺฉูู.", "next_question": "ุจุฑุง ุดุฑูุนุ ูโุชูุงูุฏ ฺฉ ุงุฒ ฺุงูุดโุจุฑุงูฺฏุฒุชุฑู ูพุฑูฺูโูุง ฺฉู ุฏุฑ ุขู ููุด ฺฉูุฏ ุฏุงุดุชุฏ ุฑุง ุชูุตู ฺฉูุฏ ู ุจฺฏูุฏ ฺฺฏููู ุจุง ููุงูุน ุขู ููุงุจูู ฺฉุฑุฏุฏุ", "end_interview": false}}
ูุซุงู ุจุฑุง ุงุฏุงูู ฺฏูุชฺฏู: {{"feedback": "ุฏุฑฺฉ ูโฺฉูู ฺฉู ูุฏุฑุช ุฐููุนุงู ุฏุฑ ุขู ูพุฑูฺู ฺูุฏุฑ ูโุชูุงูุณุชู ูพฺุฏู ุจุงุดู.", "next_question": "ุญุงูุง ุงฺฏุฑ ุฏุฑ ูููุนุช ูุฑุงุฑ ุจฺฏุฑุฏ ฺฉู ุจุง ฺฉ ุงุฒ ููฺฉุงุฑุงูุชุงู ุงุฎุชูุงู ูุธุฑ ุฌุฏ ุฏุฑ ููุฑุฏ ูุญูู ุงูุฌุงู ฺฉ ฺฉุงุฑ ุฏุงุดุชู ุจุงุดุฏุ ูุนูููุงู ฺฺฏููู ุงู ูุณุฆูู ุฑุง ูุฏุฑุช ูโฺฉูุฏุ", "end_interview": false}}
ูุซุงู ุจุฑุง ูพุงุงู ุฏุงุฏู: {{"feedback": "ุงุฒ ูพุงุณุฎโูุง ฺฉุงูู ู ุดูุงู ุดูุง ุจุณุงุฑ ุณูพุงุณฺฏุฒุงุฑู {user_name}. ุงุทูุงุนุงุช ุฎูุจ ุจู ุฏุณุช ุขูุฑุฏู ู ุจู ูุธุฑู ุชุตูุฑ ุฑูุดู ุงุฒ ุดูุง ูพุฏุง ฺฉุฑุฏู.", "next_question": null, "end_interview": true}}
"""
    resume_summary = ("ุฎูุงุตู ุฑุฒููู ฺฉุงุฑุจุฑ:\n" + resume_text[:1500] + "...\n" if resume_text else "ฺฉุงุฑุจุฑ ุฑุฒูููโุง ุงุฑุงุฆู ูฺฉุฑุฏู ุงุณุช.\n")
    history_for_prompt = []
    if conversation_history and conversation_history[0]["speaker"] == "ai" and conversation_history[0].get("question","").endswith("ุดุฑูุน ฺฉููุ"):
        entry = conversation_history[0]; feedback_text = entry.get('feedback','') or ""; question_text = entry.get('question','') or ""
        history_for_prompt.append(f" (ูุตุงุญุจูโฺฏุฑ): {feedback_text} {question_text}".strip())
    for entry in conversation_history[1:]:
        speaker_tag = f"{user_name} (ฺฉุงุฑุจุฑ)" if entry["speaker"] == "user" else " (ูุตุงุญุจูโฺฏุฑ)"
        content = "";
        if entry["speaker"] == "user": content = entry.get("content", "")
        else: feedback_text = entry.get('feedback','') or ""; question_text = entry.get('question','') or ""; content = f"{feedback_text} {question_text}".strip()
        history_for_prompt.append(f"{speaker_tag}: {content}")
    conversation_log_str = "\n".join(history_for_prompt)
    if not conversation_log_str and not (len(conversation_history) == 1 and conversation_history[0]["speaker"] == "ai"):
        conversation_log_str = "ฺฉุงุฑุจุฑ ุงุฒ ูุฑุญูู ุบุฑุจุงูฺฏุฑ ุนุจูุฑ ฺฉุฑุฏู ู ุงู ุงููู ุณูุงู ุดูุง ุจุฑุง ุณูุฌุด ููุงุฑุชโูุง ูุฑู ุงุณุช."
    final_prompt = f"{persona_definition}\n\n{resume_summary}\nุชุงุฑุฎฺู ฺฏูุชฺฏู ูุนู ุจุง {user_name}:\n{conversation_log_str}\n\n{core_instructions}"
    try:
        model = genai.GenerativeModel("gemini-2.0-flash")
        response = model.generate_content(final_prompt, **DEFAULT_REQUEST_OPTIONS) # Corrected variable name
        structured_output = extract_structured_response(response.text, default_question=None)
        if structured_output.get("error"):
            st.warning(f"ุฎุทุง ุฏุฑ ูพุฑุฏุงุฒุด ูพุงุณุฎ LLM: {structured_output.get('error')}.")
            if "?" in response.text and len(response.text.splitlines()) < 3 : return {"feedback": "ูุชุดฺฉุฑู.", "next_question": response.text.strip(), "end_interview": False}
            return {"feedback": "ูุดฺฉู ุฏุฑ ูพุฑุฏุงุฒุด ูพุงุณุฎ ูพุด ุขูุฏ.", "next_question": None, "end_interview": True}
        if structured_output.get("end_interview") and not structured_output.get("feedback"):
            structured_output["feedback"] = f"ุจุณุงุฑ ุฎุจ {user_name} ุนุฒุฒุ ุจู ูพุงุงู ุณูุงูุงุช ุงู ุจุฎุด ุฑุณุฏู. ูุชุดฺฉุฑู."
        return structured_output
    except Exception as e:
        st.error(f"โ ุฎุทุง ุฏุฑ ุงุฑุชุจุงุท ุจุง API: {e}")
        return {"feedback": "ูุชุงุณูุงูู ูุดฺฉู ูพุด ุขูุฏ.", "next_question": None, "end_interview": True}
    finally: st.session_state.ai_is_processing = False

def display_initial_options():
    with st.container():
        st.markdown("#### ูุทูุงู ุงุทูุงุนุงุช ุฎูุฏ ุฑุง ุจุฑุง ุดุฑูุน ูุตุงุญุจู ูุงุฑุฏ ฺฉูุฏ.")
        login_type = st.radio("ุงูุชุฎุงุจ ุฑูุด ูุฑูุฏ:", ("ูุฑูุฏ ุจุง ุดูุงุณู ฺฉุงุฑุจุฑ (ุฏุฑ ุตูุฑุช ูุฌูุฏ)", "ุขูพููุฏ ุฑุฒููู ู ูุดุฎุตุงุช ุฌุฏุฏ"), key="login_type_radio", horizontal=True)
        if login_type == "ูุฑูุฏ ุจุง ุดูุงุณู ฺฉุงุฑุจุฑ (ุฏุฑ ุตูุฑุช ูุฌูุฏ)": handle_id_login_input()
        else: handle_resume_upload_input()

def load_user_from_excel(user_id: str, excel_path: str = "D:\AliRahmani\complete\recruitment.xlsx") -> dict | None:
    try:
        df = pd.read_excel(excel_path)
        df.columns = df.columns.str.strip()

        user_row = df[df['ุดูุงุณู'].astype(str) == str(user_id)]
        if not user_row.empty:
            row = user_row.iloc[0]
            full_resume_text = f"""
๐งพ ูุงู ู ูุงู ุฎุงููุงุฏฺฏ: {row.get("ูุงู", "")} {row.get("ูุงู ุฎุงููุงุฏฺฏ", "")}
๐ค ุฌูุณุช: {row.get("ุฌูุณุช", "")}
๐ ุชุญุตูุงุช: {row.get("ููุทุน ุชุญุตู", "")} ุฏุฑ ุฑุดุชู {row.get("ุฑุดุชู ุชุญุตู", "")} ({row.get("ฺฏุฑุงุด ุชุญุตู", "")}) ุงุฒ {row.get("ุฏุงูุดฺฏุงู ูุญู ุชุญุตู", "")} ({row.get("ููุน ุฏุงูุดฺฏุงู ุชุญุตู", "")})
๐ ูุญู ุณฺฉููุช: {row.get("ูุญู ุณฺฉููุช", "")} | ุณู: {row.get("ุณู", "")} | ุชููุฏ: {row.get("ุณุงู ุชููุฏ", "")}
๐ง ููุงุฑุชโูุง ูุฑูโุงูุฒุงุฑ: {row.get("ููุงุฑุชโูุง ูุฑู ุงูุฒุงุฑ", "")}
๐ผ ุณูุงุจู ฺฉุงุฑ: {row.get("ุณูุงุจู ฺฉุงุฑ", "")}
๐ช ูุถุนุช ุฎุฏูุช ุณุฑุจุงุฒ: {row.get("ูุถุนุช ุฎุฏูุช ุณุฑุจุงุฒ", "")}
๐ฌ ุฏุฑุจุงุฑู ูู: {row.get("ุฏุฑุจุงุฑู ูู", "")}
๐ฐ ุญููู ุฏุฑุฎูุงุณุช: {row.get("ุญุฏุงูู ุญููู ูุงูุงูู", "")} ุชุง {row.get("ุญุฏุงฺฉุซุฑ ุญููู ูุงูุงูู", "")} ุชููุงู
""".strip()

            return {
                "name": row.get("ูุงู", DEFAULT_USER_NAME),
                "last_name": row.get("ูุงู ุฎุงููุงุฏฺฏ", ""),
                "gender": row.get("ุฌูุณุช", ""),
                "selected_job": row.get("ูููุนุช ุดุบู", None),
                "resume": full_resume_text
            }
        return None
    except Exception as e:
        st.error(f"โ ุฎุทุง ุฏุฑ ุจุงุฑฺฏุฐุงุฑ ูุงู ุงฺฉุณู ุง ุงูุชู ฺฉุงุฑุจุฑ: {e}")
        return None

def handle_id_login_input():
    user_id_input = st.text_input("๐ ุดูุงุณู ฺฉุงุฑุจุฑ ุดูุง:", key="user_id_input_main")

    if st.button("ุฌุณุชุฌู ู ุดุฑูุน ูุตุงุญุจู ุจุง ุดูุงุณู", key="start_with_id_button"):
        if not user_id_input:
            st.warning("ูุทูุงู ุดูุงุณู ฺฉุงุฑุจุฑ ุฎูุฏ ุฑุง ูุงุฑุฏ ฺฉูุฏ.")
            return

        st.session_state.user_id = user_id_input
        user_data = load_user_from_excel(user_id_input)

        if user_data and user_data.get("resume"):
            st.session_state.user_name = user_data.get("name", DEFAULT_USER_NAME)
            st.session_state.last_name = user_data.get("last_name", "")
            st.session_state.gender = user_data.get("gender", "")
            st.session_state.resume_text = user_data["resume"]
            st.session_state.selected_job = user_data.get("selected_job")

            if st.session_state.selected_job and st.session_state.selected_job in JOB_PROFILES:
                st.session_state.selected_job_id = JOB_PROFILES[st.session_state.selected_job]
            else:
                st.session_state.selected_job_id = None
                job_options = list(JOB_PROFILES.keys())
                selected_job_key = st.selectbox("ูุทูุงู ูููุนุช ุดุบู ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ:", job_options, key="job_selection_id_path", index=None, placeholder="ุงูุชุฎุงุจ ฺฉูุฏ...")
                if selected_job_key:
                    st.session_state.selected_job = selected_job_key
                    st.session_state.selected_job_id = JOB_PROFILES[selected_job_key]
                else:
                    st.error("ุจุฑุง ุงุฏุงูู ุจุงุฏ ฺฉ ูููุนุช ุดุบู ุงูุชุฎุงุจ ุดูุฏ.")
                    return

            st.session_state.interview_stage = "initial_greeting"
            st.rerun()
        else:
            st.error(f"โ ุดูุงุณู ยซ{user_id_input}ยป ุงูุช ูุดุฏ ุง ุฑุฒููู ูุงูุต ุงุณุช.")

def handle_resume_upload_input():
    st.session_state.user_id = "resume_" + datetime.now().strftime("%Y%m%d%H%M%S")

    uploaded_file = st.file_uploader("๐ค ุฑุฒููู (.pdf ุง .txt):", type=["pdf", "txt"], key="resume_uploader")

    job_options = list(JOB_PROFILES.keys())
    current_job_idx = job_options.index(st.session_state.selected_job) if st.session_state.selected_job in job_options else 0
    selected_job_key = st.selectbox("๐งญ ูููุนุช ุดุบู:", job_options, index=current_job_idx, key="job_selection_upload", placeholder="ุงูุชุฎุงุจ ฺฉูุฏ...")

    if selected_job_key:
        st.session_state.selected_job = selected_job_key
        st.session_state.selected_job_id = JOB_PROFILES[selected_job_key]

    if uploaded_file:
        st.session_state.resume_text = process_uploaded_file(uploaded_file)
        st.session_state.user_name = extract_name_from_resume(st.session_state.resume_text)

    if st.session_state.resume_text and uploaded_file:
        st.success("โ ุฑุฒููู ุจุงุฑฺฏุฐุงุฑ ุดุฏ.")

    if st.button("๐ค ุดุฑูุน ูุตุงุญุจู ุจุง ุฑุฒููู ู ูุดุฎุตุงุช", key="start_with_resume_button"):
        if not st.session_state.resume_text:
            st.warning("ูุทูุงู ฺฉ ูุงู ุฑุฒููู ูุนุชุจุฑ ุขูพููุฏ ฺฉูุฏ.")
        elif not st.session_state.selected_job_id:
            st.warning("ูุทูุงู ฺฉ ูููุนุช ุดุบู ุงูุชุฎุงุจ ฺฉูุฏ.")
        else:
            st.session_state.interview_stage = "initial_greeting"
            st.rerun()

def display_screening_questions():
    # This function seems to have some logical issues in the original code.
    # I've simplified it to be more robust.
    st.info("ูุฑุญูู ุบุฑุจุงูฺฏุฑ ุงููู: ูุทูุงู ุจู ุณูุงูุงุช ุฒุฑ ูพุงุณุฎ ุฏูุฏ.")

    # Display conversation history for this stage
    for entry in st.session_state.screening_conversation:
        with st.chat_message(entry["sender"], avatar="๐ค" if entry["sender"] == "bot" else "๐ค"):
            st.write(entry["message"])

    # Check if all screening questions are answered
    if st.session_state.current_screening_q_idx >= len(st.session_state.screening_questions_list):
        st.session_state.interview_stage = "dynamic_soft_skill" # Move to next stage
        # You might want to run the screening check here
        passed, reason = run_initial_screening(st.session_state.screening_answers)
        st.session_state.screening_passed = passed
        if not passed:
            st.error(f"ูุตุงุญุจู ุฏุฑ ุงู ูุฑุญูู ูุชููู ุดุฏ. ุฏูู: {reason}")
            st.session_state.interview_stage = "finished"
        else:
            st.success("ุบุฑุจุงูฺฏุฑ ุงููู ุจุง ููููุช ุงูุฌุงู ุดุฏ. ุจู ูุฑุญูู ุจุนุฏ ูโุฑูู.")
            # Add a starting message for the next stage
            st.session_state.conversation_history.append({
                "speaker": "ai",
                "feedback": "ุจุณุงุฑ ุนุงู!",
                "question": "ุงุฒ ุงูฺฉู ุชุง ุงู ูุฑุญูู ููุฑุงู ูุง ุจูุฏุฏ ูููููู. ุญุงูุง ูโุฎูุงูู ฺฉู ุนููโุชุฑ ุฏุฑ ููุฑุฏ ุชุฌุฑุจุงุช ู ูุญูู ุฑูฺฉุฑุฏ ุดูุง ุจู ูุณุงุฆู ุตุญุจุช ฺฉูู. ุจุฑุง ุดุฑูุนุ ูโุชูุงูุฏ ฺฉ ุงุฒ ฺุงูุดโุจุฑุงูฺฏุฒุชุฑู ูพุฑูฺูโูุง ฺฉู ุฏุฑ ุขู ููุด ฺฉูุฏ ุฏุงุดุชุฏ ุฑุง ุชูุตู ฺฉูุฏ ู ุจฺฏูุฏ ฺฺฏููู ุจุง ููุงูุน ุขู ููุงุจูู ฺฉุฑุฏุฏุ"
            })
            st.session_state.dynamic_question_count += 1
        st.rerun()
        return

    # If we are not waiting for an answer, post the next question
    if not st.session_state.awaiting_screening_answer:
        q = st.session_state.screening_questions_list[st.session_state.current_screening_q_idx]
        st.session_state.current_screening_question = q
        bot_message = generate_screening_question(q['id'], st.session_state.resume_text)
        st.session_state.screening_conversation.append({"sender": "bot", "message": bot_message})
        st.session_state.awaiting_screening_answer = True
        st.rerun()

    # Get user input only if we are waiting for an answer
    if st.session_state.awaiting_screening_answer:
        user_input = st.chat_input("ูพุงุณุฎ ุดูุง...")
        if user_input:
            st.session_state.screening_conversation.append({"sender": "user", "message": user_input})

            # Simple validation
            if len(user_input.strip()) < 3:
                st.session_state.screening_conversation.append({
                    "sender": "bot",
                    "message": "ููููููุ ูู ูุทูุงู ูพุงุณุฎ ุฑุง ฺฉุงููโุชุฑ ู ุฏููโุชุฑ ุจููุณุฏ."
                })
                st.rerun()
                return

            # Store the answer and move to the next question
            q = st.session_state.current_screening_question
            st.session_state.screening_answers.append({
                "question_id": q["id"],
                "question_text": q["text"],
                "answer": user_input.strip()
            })
            st.session_state.current_screening_q_idx += 1
            st.session_state.awaiting_screening_answer = False
            st.rerun()

def display_interview_interface():
    current_stage = st.session_state.interview_stage
    if current_stage == "initial_greeting":
        last_name = st.session_state.user_name.strip().split()[-1]
        with st.chat_message("assistant", avatar="๐ค"):
            st.markdown(
                f"""ุณูุงู ุขูุง {last_name}ุ ุงุฒ ุขุดูุง ุจุง ุดูุง ุฎูุดุญุงูู!
        ฺฉู ุฏุฑ ููุฑุฏ ุฎูุฏู ุจฺฏูู โ ูู ูุตุงุญุจูโฺฏุฑ ููุด ูุตููุน ุดุฑฺฉุช ุฏุงุฏู ูพุฑุฏุงุฒุงู ุจูุงู ุขูุง ูุณุชู.
        ุดูุง ูโุชูุงูุฏ ุฑูฺฉุฑุฏ ุญู ูุณุฆูู ุฎูุฏ ุฑุง ุจุง ูู ุฏุฑ ูุงู ุจฺฏุฐุงุฑุฏ ู ูุฑ ููุช ุจู ูุดฺฉู ุจุฑุฎูุฑุฏุฏ ุงุฒ ูู ุณูุงู ุจูพุฑุณุฏ.
        ุงุฏุชุงู ุจุงุดุฏ ฺฉู ุจู ุจุฑูุฑุงุฑ ุงุฑุชุจุงุท ุจุง ูู ุงุฏุงูู ุฏูุฏ.

        ูุง ุจุฑุง ูููุนุช ุดุบู **{st.session_state.selected_job}** ุจุง ุดูุง ฺฏูุชฺฏู ุฎูุงูู ฺฉุฑุฏ."""
            )

            if st.button("๐ ุงุฏุงูู ู ุดุฑูุน ุณูุงูุงุช ุงููู", key="begin_screening_button"):
                st.session_state.interview_stage = "screening"; st.rerun()
        return
    if current_stage == "screening": display_screening_questions(); return

    if current_stage == "dynamic_soft_skill":
        for entry in st.session_state.conversation_history:
            avatar_icon = "๐ค" if entry["speaker"] == "ai" else "๐ค"
            with st.chat_message(entry["speaker"], avatar=avatar_icon):
                if entry.get("feedback"): st.write(f"*{entry['feedback']}*")
                main_content = entry.get("question") if entry["speaker"] == "ai" else entry.get("content")
                if main_content: st.write(main_content)

        if (not st.session_state.conversation_history or st.session_state.conversation_history[-1]["speaker"] == "user") and not st.session_state.ai_is_processing:
            if st.session_state.dynamic_question_count < st.session_state.max_dynamic_questions:
                with st.spinner("ฺฉู ุตุจุฑ ฺฉูุฏ..."):
                    ai_response = get_next_ai_turn(st.session_state.conversation_history, st.session_state.resume_text, st.session_state.selected_job, st.session_state.user_name)
                ai_feedback, ai_question, is_ending = ai_response.get("feedback"), ai_response.get("next_question"), ai_response.get("end_interview", False)
                st.session_state.conversation_history.append({"speaker": "ai", "feedback": ai_feedback, "question": ai_question})
                if ai_question: st.session_state.dynamic_question_count += 1
                if is_ending or not ai_question: st.session_state.interview_stage = "final_analysis"
                st.rerun()
            else:
                st.session_state.conversation_history.append({"speaker": "ai", "feedback": "ุจู ุชุนุฏุงุฏ ุณูุงูุงุช ููุฑุฏ ูุธุฑ ุจุฑุง ุงู ุจุฎุด ุฑุณุฏูโุงู.", "question": "ุงุฒ ููุช ฺฉู ฺฏุฐุงุดุชุฏ ูููููู. ุฏุฑ ุญุงู ุขูุงุฏู ุณุงุฒ ุชุญูู ููุง ูุณุชู."})
                st.session_state.interview_stage = "final_analysis"; st.rerun()

        if st.session_state.conversation_history and st.session_state.conversation_history[-1]["speaker"] == "ai" and \
           st.session_state.conversation_history[-1].get("question") and current_stage == "dynamic_soft_skill":
            user_answer = st.chat_input("ูพุงุณุฎ ุดูุง...", key=f"dynamic_ans_input_{st.session_state.dynamic_question_count}")
            if user_answer:
                st.session_state.conversation_history.append({"speaker": "user", "content": user_answer.strip()})
                st.rerun()

    elif current_stage == "final_analysis":
        with st.container():
            perform_final_analysis()
    elif current_stage == "finished":
        with st.container():
            if st.session_state.get("screening_passed", True): st.balloons()
            st.success("ูุตุงุญุจู ุดูุง ุจู ูพุงุงู ุฑุณุฏ. ุงุฒ ููุช ฺฉู ฺฏุฐุงุดุชุฏ ุณูพุงุณฺฏุฒุงุฑู!")
            offer_reset_confirmation()

def perform_final_analysis():
    st.info("ุฏุฑ ุญุงู ุขูุงุฏู ุณุงุฒ ุชุญูู ููุง ูุตุงุญุจู ุดูุง...")
    user_id_for_file = clean_excel_text(st.session_state.get("user_id", "unknown_user"))
    history_for_prompt = []
    if st.session_state.get("screening_answers"):
        history_for_prompt.append("\n--- ูพุงุณุฎ ุจู ุณูุงูุงุช ุบุฑุจุงูฺฏุฑ ุงููู ---")
        for sa in st.session_state.screening_answers: history_for_prompt.append(f"ุณูุงู: {sa['question_text']}\nูพุงุณุฎ ุดูุง: {sa['answer']}")
        history_for_prompt.append("--- ูพุงุงู ุจุฎุด ุบุฑุจุงูฺฏุฑ ---\n")
    for e in st.session_state.conversation_history:
        actor = "ุดุฑฺฉุช ุฏุงุฏู ูพุฑุฏุงุฒุงู ุจูุงู ุขูุง (ูุตุงุญุจูโฺฏุฑ)" if e['speaker'] == 'ai' else f"{st.session_state.user_name} (ฺฉุงุฑุจุฑ)"
        text = "";
        if e['speaker'] == 'ai':
            if e.get('feedback'): text += f"[ุจุงุฒุฎูุฑุฏ : {e['feedback']}] "
            if e.get('question'): text += e['question']
        else: text = e.get('content', '')
        history_for_prompt.append(f"{actor}: {text.strip()}")
    analysis_prompt_template = f"""
ุดูุง ฺฉ ูุฏุฑ ุงุฑุดุฏ ููุงุจุน ุงูุณุงู ุฏุฑ ุดุฑฺฉุช ยซูุงูุงยป ูุณุชุฏ ู ุจุงุฏ ฺฉ ฺฏุฒุงุฑุด ฺฉุงูู ุชุญูู ุงุฒ ฺฉุงูุฏุฏุง ({st.session_state.user_name}) ุจุฑุง ูููุนุช ุดุบู ({st.session_state.selected_job}) ุงุฑุงุฆู ุฏูุฏ.
ุฑุฒููู (ุฎูุงุตู): {st.session_state.resume_text[:1500] + "..." if st.session_state.resume_text else "ุงุฑุงุฆู ูุดุฏู"}
---
ุชุงุฑุฎฺู ฺฉุงูู ูุตุงุญุจู (ุดุงูู ุณูุงูุงุช ุบุฑุจุงูฺฏุฑุ ุจุงุฒุฎูุฑุฏูุง ุณูุงูุงุช ู ูพุงุณุฎโูุง ฺฉุงุฑุจุฑ):
{"\n".join(history_for_prompt)}
---
ฺฏุฒุงุฑุด ุชุญูู ุฎูุฏ ุฑุง ุฏุฑ ุจุฎุดโูุง ุฒุฑ ุงุฑุงุฆู ุฏูุฏ:
1.  ๐ **ุฎูุงุตู ฺฉู:** (ุญุฏูุฏ ตฐ-ฑฐฐ ฺฉููู) ฺฉ ูพุงุฑุงฺฏุฑุงู ุฏุฑ ููุฑุฏ ฺฉุงูุฏุฏุง ู ุชูุงุณุจ ฺฉู ุงู ุจุง ูููุนุช ุดุบู ุจุง ุชูุฌู ุจู ููุงุฑุชโูุง ูุฑู ุงุฑุฒุงุจ ุดุฏู.
2.  ๐ง **ุชุญูู ููุงุฑุชโูุง ูุฑู ฺฉูุฏ:** ุจุฑ ุงุณุงุณ ฺฉู ฺฏูุชฺฏูุ ููุงุฑุชโูุง ูุฑู ุงุตู ูุงููุฏ ุญู ูุณุฆููุ ุงุฑุชุจุงุทุงุชุ ฺฉุงุฑ ุชูุ ุงูุทุจุงูโูพุฐุฑุ ุงุจุชฺฉุงุฑุ ูุฏุฑุช ุงุณุชุฑุณุ ุงุฏฺฏุฑ ู ุงุฎูุงู ุญุฑููโุง ุฑุง ุชุญูู ฺฉูุฏ. ุจุฑุง ูุฑ ููุงุฑุชุ ุดูุงูุฏ ูุซุจุช ุง ููู ุงุฒ ฺฏูุชฺฏู ุฐฺฉุฑ ฺฉูุฏ.
3.  ๐ฏ **ููุงุท ููุช ุงุตู:** ณ ุชุง ต ููุทู ููุช ุงุตู ูุฑุฏ ุฏุฑ ุฒููู ููุงุฑุชโูุง ูุฑู ฺฉู ุจู ูุถูุญ ุฏุฑ ูุตุงุญุจู ูุดุงูุฏู ุดุฏ ุฑุง ูุณุช ฺฉูุฏ.
4.  ๐ค **ููุงุฑุฏ ูุงุจู ุชุงูู ุง ุฑุณฺฉโูุง:** ููุงุฑุฏ ูฺฏุฑุงูโฺฉููุฏูุ ูพุงุณุฎโูุง ูุจููุ ุง ููุงุท ฺฉู ูุงุฒ ุจู ุจุฑุฑุณ ุจุดุชุฑ ุฏุฑ ูุตุงุญุจู ุญุถูุฑ ุฏุงุฑูุฏ ุฑุง ูุดุฎุต ฺฉูุฏ.
5.  ๐ **ูพุดููุงุฏ ููุง ู ุฏูู:** ุจู ุทูุฑ ูุงุถุญ ูุดุฎุต ฺฉูุฏ ฺฉู ุขุง ุงู ูุฑุฏ ุฑุง ุจุฑุง ูุฑุญูู ุจุนุฏ (ูุตุงุญุจู ุชุฎุตุต ุญุถูุฑ) ูพุดููุงุฏ ูโฺฉูุฏ ุง ุฎุฑ. ุฏูู ุงุตู ูพุดููุงุฏ ุง ุนุฏู ูพุดููุงุฏ ุฎูุฏ ุฑุง ุฏุฑ ฺฉ ุง ุฏู ุฌููู ุจุงู ฺฉูุฏ.
"""
    try:
        with st.spinner("ุฏุฑ ุญุงู ุงูุฌุงู ุชุญูู ููุง ุชูุณุท ููุด ูุตููุน..."):
            model_analyzer = genai.GenerativeModel("gemini-2.0-flash")
            generation_config = genai.types.GenerationConfig(
                temperature=0.6,
                top_p=0.95,
                top_k=40,
                max_output_tokens=1024
            )
            response_analysis = model_analyzer.generate_content(
                analysis_prompt_template,
                generation_config=generation_config
            )
            analysis_text = response_analysis.text
        st.markdown("---"); st.markdown("### ๐ ุชุญูู ููุง ูุตุงุญุจู:"); st.markdown(analysis_text)
        save_interview_results(user_id_for_file, analysis_text, st.session_state.screening_answers, st.session_state.conversation_history)
        st.session_state.interview_stage = "finished"; st.rerun()
    except genai_types.BlockedPromptException as e: st.error(f"โ ุฏุฑุฎูุงุณุช ุชุญูู ุชูุณุท API ูุณุฏูุฏ ุดุฏ: {e}")
    except Exception as e: st.error(f"โ ุฎุทุง ุฏุฑ ุชุญูู ููุง: {e}")
    st.session_state.interview_stage = "finished"

def save_interview_results(user_id_str: str, analysis_report: str, screening_log: list, conversation_log: list):
    downloads_folder = Path.home() / "Downloads" / DOWNLOADS_DIR_NAME
    downloads_folder.mkdir(parents=True, exist_ok=True)
    general_excel_path = downloads_folder / "all_interview_results_v3.xlsx"
    data_to_save = {
        "user_id": user_id_str, "user_name": clean_excel_text(st.session_state.user_name),
        "selected_job": clean_excel_text(st.session_state.selected_job),
        "resume_summary": clean_excel_text(st.session_state.resume_text[:700] + "..." if st.session_state.resume_text else ""),
        "screening_answers": clean_excel_text(json.dumps(screening_log, ensure_ascii=False, indent=2)),
        "conversation_history": clean_excel_text(json.dumps(conversation_log, ensure_ascii=False, indent=2)),
        "full_analysis": clean_excel_text(analysis_report)
    }
    new_row_df = pd.DataFrame([data_to_save])
    try:
        df_to_save = new_row_df
        if general_excel_path.exists():
            try: existing_df = pd.read_excel(general_excel_path); df_to_save = pd.concat([existing_df, new_row_df], ignore_index=True)
            except Exception as read_err: st.warning(f"ุฎุทุง ุฏุฑ ุฎูุงูุฏู ูุงู ุงฺฉุณู ููุฌูุฏุ ูุงู ุฌุฏุฏ ุงุฌุงุฏ ูโุดูุฏ: {read_err}")
        df_to_save.to_excel(general_excel_path, index=False, engine='openpyxl')
        st.success(f"โ ุงุทูุงุนุงุช ูุตุงุญุจู ุฏุฑ '{general_excel_path.name}' (ูพูุดู Downloads/{DOWNLOADS_DIR_NAME}) ุฐุฎุฑู ุดุฏ.")
    except Exception as e: st.error(f"โ ุฎุทุง ุฏุฑ ุฐุฎุฑู ูุงู Excel: {e}")
    analysis_bytes = analysis_report.encode('utf-8')
    st.download_button(label="๐ ุฏุงูููุฏ ุชุญูู ุงู ูุตุงุญุจู (ูุชู)",data=analysis_bytes,
        file_name=f"analysis_{user_id_str}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", mime="text/plain")

def offer_reset_confirmation():
    if "confirm_reset" not in st.session_state: st.session_state.confirm_reset = False
    if st.button("ุดุฑูุน ูุตุงุญุจู ุฌุฏุฏ", key="reset_initial"): st.session_state.confirm_reset = True; st.rerun()
    if st.session_state.confirm_reset:
        st.warning("**ุขุง ูุทูุฆู ูุณุชุฏุ** ุดุฑูุน ูุตุงุญุจู ุฌุฏุฏ ุงุทูุงุนุงุช ูุนู ุฑุง ุงุฒ ุตูุญู ูพุงฺฉ ูโฺฉูุฏ (ุงูุง ุฏุฑ ูุงู Excel ุฐุฎุฑู ุดุฏู ุงุณุช).")
        col1, col2, _ = st.columns([1,1,3])
        if col1.button("ุจููุ ูพุงฺฉ ฺฉู", key="reset_yes", type="primary"): reset_for_new_interview(); st.rerun()
        if col2.button("ููุ ููุตุฑู ุดุฏู", key="reset_no"): st.session_state.confirm_reset = False; st.rerun()

# --- Main Application Flow ---
def main():
    st.set_page_config(
        page_title="ูุตุงุญุจูโฺฏุฑ ููุดููุฏ ุดุฑฺฉุช ุฏุงุฏู ูพุฑุฏุงุฒุงู ุจูุงู ุขูุง",
        layout="centered",
        initial_sidebar_state="collapsed",
    )

    primary_color = "#2563EB"
    background_color = "#F3F4F6"
    card_background_color = "#FFFFFF"
    text_color = "#1F2937"
    button_text_color = "#FFFFFF"
    border_color_soft = "#E5E7EB"
    ai_chat_bubble_color = "#DBEAFE" # Tailwind blue-100 (Light Blue for AI)
    user_chat_bubble_color = "#E0E7FF" # Tailwind indigo-100 (Light Indigo for User)


    custom_css = f"""
    <style>
        /* --- Base Theme Application --- */
        body, .main {{
            direction: rtl;
            text-align: right;
            font-family: 'IRANSans', 'Tahoma', sans-serif !important;
            background-color: {background_color} !important;
            color: {text_color};
            line-height: 1.6; /* Improved default line height */
        }}
        .block-container {{
            direction: rtl;
            text-align: right;
            font-family: 'IRANSans', 'Tahoma', sans-serif !important;
            color: {text_color};
            max-width: 800px;
            padding: 1.5rem;
            margin: 1rem auto;
            border-radius: 0.75rem;
            background-color: {card_background_color};
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }}

        /* --- Input Fields General Styling --- */
        textarea, input, .stTextInput > div > div > input, .stTextArea > div > div > textarea {{
            font-family: 'IRANSans', 'Tahoma', sans-serif !important;
            border-radius: 0.375rem;
            border: 1px solid {border_color_soft};
            background-color: #FFFFFF;
            padding: 0.5rem 0.75rem; /* Added padding to input fields */
        }}
        textarea:focus, input:focus,
        .stTextInput > div > div > input:focus,
        .stTextArea > div > div > textarea:focus,
        div[data-testid="stSelectbox"] > div:focus-within {{ /* For selectbox focus */
            border-color: {primary_color} !important;
            box-shadow: 0 0 0 0.2rem {primary_color}40 !important;
            outline: none !important;
        }}

        /* Selectbox specific styling for consistency */
        div[data-testid="stSelectbox"] > div {{
            border-radius: 0.375rem;
            border: 1px solid {border_color_soft};
            background-color: #FFFFFF;
        }}
        div[data-testid="stSelectbox"] div[data-baseweb="select"] > div {{ /* Target inner part for padding */
             padding-top: 0.1rem;
             padding-bottom: 0.1rem;
        }}


        /* --- Headings --- */
        div[data-testid="stAppViewContainer"] h1 {{ /* Main page title (st.title) */
            color: {primary_color};
            text-align: center;
            padding-bottom: 0.75rem;
            margin-bottom: 1.5rem;
            font-size: 2rem; /* Slightly reduced for balance */
        }}
        .block-container h3, .block-container h4 {{
            color: {primary_color};
            margin-top: 1.5rem;
            margin-bottom: 0.75rem;
            border-bottom: 1px solid {primary_color}55;
            padding-bottom: 0.25rem;
            font-size: 1.25rem; /* Slightly larger sub-headers */
        }}

        /* --- Button Styling (General) --- */
        .stButton > button {{
            background-color: {primary_color};
            color: {button_text_color};
            border: none;
            padding: 0.5rem 1rem; /* Slightly adjusted padding */
            border-radius: 0.375rem; /* Consistent with inputs */
            font-weight: 500;
            transition: background-color 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
            box-shadow: 0 1px 2px 0 rgba(0, 0, 0, 0.05); /* Softer shadow */
        }}
        .stButton > button:hover {{
            background-color: #1D4ED8;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06); /* Lift on hover */
        }}
        .stButton > button:active {{
            background-color: #1E40AF;
            box-shadow: inset 0 2px 4px 0 rgba(0, 0, 0, 0.06); /* Inset shadow on active */
        }}

        /* --- Specific container styling for cards (if used internally) --- */
        .custom-card {{
            background-color: {card_background_color};
            padding: 1.5rem; /* More padding for internal cards */
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgba(0,0,0,0.07), 0 2px 4px -1px rgba(0,0,0,0.04); /* Softer shadow for internal cards */
            margin-bottom: 1.5rem;
        }}

        /* Progress Bar styling */
        .stProgress > div > div > div > div {{ background-color: {primary_color}; }}

        /* Radio button styling */
        .stRadio > label {{ /* The label for the radio group */
            font-size: 1.1rem;
            font-weight: 500;
            margin-bottom: 0.5rem;
        }}
        .stRadio > div {{ /* The container for radio options */
            padding: 0.25rem;
        }}

        /* Chat input area */
        div[data-testid="stChatInputForm"] {{ /* Target the form around chat input */
            border-top: 1px solid {border_color_soft};
            padding-top: 0.75rem;
            margin-top: 0.75rem;
        }}
        div[data-testid="stChatInput"] > div > div > textarea {{
             background-color: {background_color}; /* Lighter background for chat input textarea */
             border: 1px solid {border_color_soft};
        }}
        div[data-testid="stChatInput"] {{ background-color: {card_background_color}; }} /* Ensure chat input bar matches card */

        /* --- Chat Message Styling --- */
        div[data-testid="stChatMessage"] {{ margin-bottom: 1rem; }}

        /* User messages styling */
        div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) {{
            display: flex;
            flex-direction: row-reverse; /* Avatar on the right for user in RTL */
        }}
        div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-user"]) div[data-testid="stChatMessageContent"] {{
            background-color: {user_chat_bubble_color};
            border-radius: 1rem 1rem 0.25rem 1rem; /* Custom shape for user */
            padding: 0.75rem 1rem;
            max-width: 75%;
            color: {text_color};
        }}

        /* AI (assistant) messages styling */
         div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-assistant"]) {{
            display: flex;
            flex-direction: row; /* Avatar on the left for AI in RTL (default) */
        }}
        div[data-testid="stChatMessage"]:has(div[data-testid="chatAvatarIcon-assistant"]) div[data-testid="stChatMessageContent"] {{
            background-color: {ai_chat_bubble_color};
            border-radius: 1rem 1rem 1rem 0.25rem; /* Custom shape for AI */
            padding: 0.75rem 1rem;
            max-width: 75%;
            color: {text_color};
        }}
        /* Avatar icon containers */
        div[data-testid="chatAvatarIcon-assistant"] > div,
        div[data-testid="chatAvatarIcon-user"] > div {{
            color: white; /* Emoji color */
            font-size: 1.5rem; /* Adjust emoji size */
        }}
        div[data-testid="stChatMessageContent"] p {{ margin-bottom: 0.25rem; line-height: 1.6; }}
        div[data-testid="stChatMessageContent"] em {{
            display: block; margin-bottom: 0.5rem;
            font-size: 0.95em; opacity: 0.9; font-style: italic;
        }}

    </style>
    """
    st.markdown(custom_css, unsafe_allow_html=True)

    initialize_session_state()
    # --- Main Check ---
    # Call configure_api() at the beginning. If it returns False, stop the app.
    if not configure_api():
        # The error message is already displayed inside the configure_api function
        return

    current_stage = st.session_state.interview_stage 
    if current_stage == "initial_setup": 
        st.title("๐ค ุจู ูุตุงุญุจูโฺฏุฑ ููุดููุฏ ุดุฑฺฉุช ุฏุงุฏู ูพุฑุฏุงุฒุงู ุจูุงู ุขูุง ุฎูุด ุขูุฏุฏ") 
        st.markdown("---") 
        display_initial_options() 

        # ๐งช ุดุจูโุณุงุฒ ฺฉุงูู ูุตุงุญุจู
        if st.button("๐งช ุดุจูโุณุงุฒ ฺฉุงูู ูุตุงุญุจู (LLM ูพุงุณุฎ ุฏูุฏ)", key="simulate_llm_test"): 
            st.session_state.resume_text = "ูููุฏุณ ูุฑูโุงูุฒุงุฑ ุจุง ต ุณุงู ุณุงุจูู ุฏุฑ ูพุฑูฺูโูุง ERP ู ุชูุณุนู ุงูพูฺฉุดูโูุง ูุจุชู ุจุฑ ููุด ูุตููุน." 
            st.session_state.user_name = "ูุญูุฏ ุงูู" 
            st.session_state.selected_job = "ฺฉุงุฑุดูุงุณ ุชุญููฺฏุฑ ุฏุงุฏู" 
            st.session_state.selected_job_id = JOB_PROFILES[st.session_state.selected_job] 
            st.session_state.screening_answers = [ 
                {"question_id": "salary", "question_text": "ุญููู ฺูุฏุฑุ", "answer": "ฒต ูููู ุชููุงู"}, 
                {"question_id": "availability", "question_text": "ุฏุงูุดุฌูุ", "answer": "ูุงุฑุบโุงูุชุญุตู ู ุชูุงู ููุช"}, 
                {"question_id": "military", "question_text": "ูุถุนุช ูุธุงู ูุธููุ", "answer": "ูพุงุงู ุฎุฏูุช"}, 
            ] 
            st.session_state.conversation_history = [] 
            st.session_state.dynamic_question_count = 0 
            st.session_state.interview_stage = "dynamic_soft_skill" 

            def simulate_full_conversation(): 
                for _ in range(int(MAX_DYNAMIC_QUESTIONS)): 
                    ai_turn = get_next_ai_turn( 
                        st.session_state.conversation_history, 
                        st.session_state.resume_text, 
                        st.session_state.selected_job, 
                        st.session_state.user_name 
                    ) 
                    st.session_state.conversation_history.append({ 
                        "speaker": "ai", 
                        "feedback": ai_turn.get("feedback", ""), 
                        "question": ai_turn.get("next_question", "") 
                    }) 
                    if ai_turn.get("end_interview") or not ai_turn.get("next_question"): 
                        st.session_state.interview_stage = "final_analysis" 
                        break 

                    # ูพุงุณุฎ ุดุจูโุณุงุฒโุดุฏู ุชูุณุท ูุฏู
                    user_response = genai.GenerativeModel("gemini-2.0-flash").generate_content( 
                        f"ุจู ุนููุงู ฺฉ ฺฉุงุฑุฌู ุญุฑููโุงุ ุจู ุงู ุณูุงู ูพุงุณุฎ ุฏูุฏ: {ai_turn['next_question']}", 
                        generation_config=genai.types.GenerationConfig(temperature=0.7, max_output_tokens=256) 
                    ).text.strip() 
                    st.session_state.conversation_history.append({"speaker": "user", "content": user_response}) 
                st.session_state.interview_stage = "final_analysis"
                st.rerun()

            simulate_full_conversation()
            
                 

    elif current_stage in ["initial_greeting", "screening", "dynamic_soft_skill", "final_analysis", "finished"]:
        job_title_display = f" (ุจุฑุง ูููุนุช: {st.session_state.selected_job or 'ูุงูุดุฎุต'})" if st.session_state.selected_job else ""
        first_name = st.session_state.user_name.strip().split()[0]
        last_name = st.session_state.user_name.strip().split()[-1]
        full_name_fixed = f"{first_name} {last_name}"

        st.title(f" ูุตุงุญุจู ุจุง {full_name_fixed}{job_title_display}")
        st.markdown("---");
        display_interview_interface()
    
if __name__ == "__main__":
    main()



 